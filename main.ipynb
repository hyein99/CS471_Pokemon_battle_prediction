{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "from Graph import GraphSage, GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "deterministic = True\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokemon.csv and combats.csv\n",
    "pokemon_data = pd.read_csv('./dataset/pokemon.csv')\n",
    "combats_data = pd.read_csv('./dataset/combats.csv')\n",
    "\n",
    "# Encode vertex values to unique integers\n",
    "label_encoder = LabelEncoder()\n",
    "pokemon_data['#'] = label_encoder.fit_transform(pokemon_data['#'])\n",
    "combats_data[['First_pokemon', 'Second_pokemon', 'Winner']] = \\\n",
    "    combats_data[['First_pokemon', 'Second_pokemon', 'Winner']].apply(label_encoder.transform)\n",
    "\n",
    "features_to_normalize = ['HP', 'Attack', 'Defense', 'Speed', 'Generation', 'Sp. Atk', 'Sp. Def']\n",
    "features_else = ['Type 1_Bug', 'Type 1_Dark', 'Type 1_Dragon', 'Type 1_Electric',\n",
    "              'Type 1_Fairy', 'Type 1_Fighting', 'Type 1_Fire', 'Type 1_Flying',\n",
    "              'Type 1_Ghost', 'Type 1_Grass', 'Type 1_Ground', 'Type 1_Ice',\n",
    "              'Type 1_Normal', 'Type 1_Poison', 'Type 1_Psychic', 'Type 1_Rock',\n",
    "              'Type 1_Steel', 'Type 1_Water', 'Type 2_Bug', 'Type 2_Dark',\n",
    "              'Type 2_Dragon', 'Type 2_Electric', 'Type 2_Fairy', 'Type 2_Fighting',\n",
    "              'Type 2_Fire', 'Type 2_Flying', 'Type 2_Ghost', 'Type 2_Grass',\n",
    "              'Type 2_Ground', 'Type 2_Ice', 'Type 2_Normal', 'Type 2_Poison',\n",
    "              'Type 2_Psychic', 'Type 2_Rock', 'Type 2_Steel', 'Type 2_Water']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pokemon_data[features_to_normalize] = \\\n",
    "    scaler.fit_transform(pokemon_data[features_to_normalize])\n",
    "\n",
    "pokemon_data = pd.get_dummies(pokemon_data, columns=['Type 1', 'Type 2'])\n",
    "pokemon_data[features_else] = \\\n",
    "    pokemon_data[features_else].astype(int)\n",
    "\n",
    "pokemon_data['Legendary'] = pokemon_data['Legendary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split combats data into train and test\n",
    "train_combats, test_combats = train_test_split(combats_data, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Extract unique vertex values from train_combats and test_combats\n",
    "train_vertices = set(train_combats['First_pokemon']).union(set(train_combats['Second_pokemon']))\n",
    "test_vertices = set(test_combats['First_pokemon']).union(set(test_combats['Second_pokemon']))\n",
    "\n",
    "# Split pokemon data into train and test based on the vertices\n",
    "train_pokemon = pokemon_data[pokemon_data['#'].isin(train_vertices)]\n",
    "test_pokemon = pokemon_data[pokemon_data['#'].isin(test_vertices)]\n",
    "\n",
    "# Decode vertex values back to original values if needed\n",
    "train_pokemon['#'] = label_encoder.inverse_transform(train_pokemon['#'])\n",
    "test_pokemon['#'] = label_encoder.inverse_transform(test_pokemon['#'])\n",
    "\n",
    "# Set \"#\" as index for train_pokemon and test_pokemon dataframes\n",
    "train_pokemon.set_index('#', inplace=True)\n",
    "test_pokemon.set_index('#', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_to_normalize + features_else\n",
    "\n",
    "X_data = pokemon_data[features].values\n",
    "X_data = torch.tensor(X_data, dtype=torch.float)\n",
    "\n",
    "# for train dataset\n",
    "X_train = train_pokemon[features].values\n",
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "edges_train = []\n",
    "neg_edge_index_train = []\n",
    "\n",
    "for _, row in train_combats.iterrows():\n",
    "    first_pokemon = row['First_pokemon']\n",
    "    second_pokemon = row['Second_pokemon']\n",
    "    winner = row['Winner']\n",
    "\n",
    "    if first_pokemon == winner:\n",
    "      edges_train.append((second_pokemon, first_pokemon))\n",
    "      neg_edge_index_train.append((first_pokemon, second_pokemon))\n",
    "\n",
    "    else:\n",
    "      edges_train.append((first_pokemon, second_pokemon))\n",
    "      neg_edge_index_train.append((second_pokemon, first_pokemon))\n",
    "\n",
    "neg_edge_index_train = torch.tensor(neg_edge_index_train, dtype=torch.long).t()\n",
    "edge_index_train = torch.tensor(edges_train, dtype=torch.long).t()\n",
    "\n",
    "data_train = Data(x=X_data, edge_index=edge_index_train, neg_edge_index = neg_edge_index_train)\n",
    "train_loader = DataLoader([data_train], batch_size=1, shuffle=True)\n",
    "\n",
    "# for test dataset\n",
    "X_test = test_pokemon[features].values\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "edges_test = []\n",
    "neg_edge_index_test = []\n",
    "\n",
    "for _, row in test_combats.iterrows():\n",
    "    first_pokemon = row['First_pokemon']\n",
    "    second_pokemon = row['Second_pokemon']\n",
    "    winner = row['Winner']\n",
    "\n",
    "    if first_pokemon == winner:\n",
    "      edges_test.append((second_pokemon, first_pokemon))\n",
    "      neg_edge_index_test.append((first_pokemon, second_pokemon))\n",
    "\n",
    "    else:\n",
    "      edges_test.append((first_pokemon, second_pokemon))\n",
    "      neg_edge_index_test.append((second_pokemon, first_pokemon))\n",
    "\n",
    "edge_index_test = torch.tensor(edges_test, dtype=torch.long).t()\n",
    "neg_edge_index_test = torch.tensor(neg_edge_index_test, dtype=torch.long).t()\n",
    "\n",
    "data_test = Data(x=X_data, edge_index=edge_index_test, neg_edge_index= neg_edge_index_test)\n",
    "test_loader = DataLoader([data_test], batch_size=1, shuffle=False)\n",
    "\n",
    "# for total data\n",
    "edge = edges_train\n",
    "edge.extend(edges_test)\n",
    "edge_index = torch.tensor(edge, dtype=torch.long).t()\n",
    "\n",
    "data_total = Data(x=X_data, edge_index = edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train, Test, Predict Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        pos_edge_index = data.edge_index\n",
    "        neg_edge_index = data.neg_edge_index\n",
    "\n",
    "        pos_head = out[pos_edge_index[0]]\n",
    "        pos_tail = out[pos_edge_index[1]]\n",
    "        neg_head = out[neg_edge_index[0]]\n",
    "        neg_tail = out[neg_edge_index[1]]\n",
    "\n",
    "        pos_pred = model.predict(pos_head, pos_tail)\n",
    "        neg_pred = model.predict(neg_head, neg_tail)\n",
    "\n",
    "        pos_loss = F.binary_cross_entropy_with_logits(pos_pred, torch.ones_like(pos_pred))\n",
    "        neg_loss = F.binary_cross_entropy_with_logits(neg_pred, torch.zeros_like(neg_pred))\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    auc = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index)\n",
    "\n",
    "            pos_edge_index = data.edge_index\n",
    "            neg_edge_index = data.neg_edge_index\n",
    "\n",
    "            pos_head = out[pos_edge_index[0]]\n",
    "            pos_tail = out[pos_edge_index[1]]\n",
    "            neg_head = out[neg_edge_index[0]]\n",
    "            neg_tail = out[neg_edge_index[1]]\n",
    "\n",
    "            pos_pred = model.predict(pos_head, pos_tail)\n",
    "            neg_pred = model.predict(neg_head, neg_tail)\n",
    "            preds = torch.cat([pos_pred, neg_pred])\n",
    "\n",
    "            pos_labels = torch.ones_like(pos_pred)\n",
    "            neg_labels = torch.zeros_like(neg_pred)\n",
    "            labels = torch.cat([pos_labels, neg_labels])\n",
    "\n",
    "            auc += roc_auc_score(labels.cpu(), preds.cpu())\n",
    "\n",
    "    return auc / len(loader)\n",
    "\n",
    "def predict(model, head, tail, data, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index)\n",
    "        head_feature = out[head]\n",
    "        tail_feature = out[tail]\n",
    "        score = model.predict(head_feature, tail_feature)\n",
    "        reverse_score = model.predict(tail_feature, head_feature)\n",
    "        return torch.sigmoid(score).item(), torch.sigmoid(reverse_score).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model from [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]\n",
    "def train_model(epoch, model_type, data_train, data_test, train_loader, test_loader, device):\n",
    "    EPOCH = epoch    \n",
    "    MODEL = model_type\n",
    "\n",
    "    if MODEL == \"GCN\":\n",
    "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"gcn\")\n",
    "    elif MODEL == \"GraphSage_mean\":\n",
    "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"mean\")\n",
    "    elif MODEL == \"GraphSage_maxpool\":\n",
    "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"maxpool\")\n",
    "    elif MODEL == \"GAT\":\n",
    "        model = GAT(dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, dropout = 0.5, alpha = 0.2, num_heads = 8)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    data_train = data_train.to(device)\n",
    "    data_test = data_test.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    patience = 3 # for early stopping\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        loss = train(model, optimizer, train_loader, device)\n",
    "        if epoch % 10 == 0:\n",
    "            test_auc = test(model, test_loader, device)\n",
    "            train_auc = test(model, train_loader, device)\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Test AUC: {test_auc:.4f}')\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve == patience:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "    return model\n",
    "\n",
    "# calculate prediction accuracy\n",
    "def test_model(model, data_total, data_test, device):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    head_list, tail_list = data_test.edge_index\n",
    "    head_list = list(head_list)\n",
    "    tail_list = list(tail_list)\n",
    "\n",
    "    pos = 0\n",
    "    for idx in range(len(head_list)):\n",
    "        head = head_list[idx]\n",
    "        tail = tail_list[idx]\n",
    "        prediction, reverse_prediction = predict(model, head, tail, data_total, device)\n",
    "        if prediction > reverse_prediction:\n",
    "            pos += 1\n",
    "\n",
    "    print(f\"Prediction accuracy: {pos/len(head_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# select model from model_types\n",
    "model_types = [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = train_model(300, \"GCN\", data_train, data_test, train_loader, test_loader, device)\n",
    "test_model(gcn_model, data_total, data_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_mean_model = train_model(300, \"GraphSage_mean\", data_train, data_test, train_loader, test_loader, device)\n",
    "test_model(graphsage_mean_model, data_total, data_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_max_model = train_model(300, \"GraphSage_maxpool\", data_train, data_test, train_loader, test_loader, device)\n",
    "test_model(graphsage_max_model, data_total, data_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_model = train_model(300, \"GAT\", data_train, data_test, train_loader, test_loader, device)\n",
    "test_model(gat_model, data_total, data_test, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
