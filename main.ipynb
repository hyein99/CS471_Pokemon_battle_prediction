{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkSe5fXKrY8G"
      },
      "outputs": [],
      "source": [
        "!pip install gdown==5.2.0\n",
        "!pip install matplotlib==3.7.2\n",
        "!pip install numpy==1.24.3\n",
        "!pip install pandas==2.0.3\n",
        "!pip install scikit-learn==1.3.0\n",
        "!pip install torch==2.1.2\n",
        "!pip install torch-geometric==2.5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axJ9tf7vswKn",
        "outputId": "720dbbd8-56dc-4fbe-99b0-6ae7cf04f068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CS471_Pokemon_battle_prediction'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 38 (delta 12), reused 24 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (38/38), 302.25 KiB | 552.00 KiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Dataset download from Google Drive using gdown\n",
        "\"\"\"\n",
        "\n",
        "!git clone https://github.com/hyein99/CS471_Pokemon_battle_prediction.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNybONnWrY8G"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tizSUrJmrY8H"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5xMrCdFArY8H"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "deterministic = True\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "if deterministic:\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\ttorch.backends.cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQXcMk2erY8H"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "C_0Xb4tPrY8H"
      },
      "outputs": [],
      "source": [
        "# Load pokemon.csv and combats.csv\n",
        "pokemon_data = pd.read_csv('./CS471_Pokemon_battle_prediction/dataset/pokemon.csv')\n",
        "combats_data = pd.read_csv('./CS471_Pokemon_battle_prediction/dataset/combats.csv')\n",
        "\n",
        "# Encode vertex values to unique integers\n",
        "label_encoder = LabelEncoder()\n",
        "pokemon_data['#'] = label_encoder.fit_transform(pokemon_data['#'])\n",
        "combats_data[['First_pokemon', 'Second_pokemon', 'Winner']] = \\\n",
        "    combats_data[['First_pokemon', 'Second_pokemon', 'Winner']].apply(label_encoder.transform)\n",
        "\n",
        "features_to_normalize = ['HP', 'Attack', 'Defense', 'Speed', 'Generation', 'Sp. Atk', 'Sp. Def']\n",
        "features_else = ['Type 1_Bug', 'Type 1_Dark', 'Type 1_Dragon', 'Type 1_Electric',\n",
        "              'Type 1_Fairy', 'Type 1_Fighting', 'Type 1_Fire', 'Type 1_Flying',\n",
        "              'Type 1_Ghost', 'Type 1_Grass', 'Type 1_Ground', 'Type 1_Ice',\n",
        "              'Type 1_Normal', 'Type 1_Poison', 'Type 1_Psychic', 'Type 1_Rock',\n",
        "              'Type 1_Steel', 'Type 1_Water', 'Type 2_Bug', 'Type 2_Dark',\n",
        "              'Type 2_Dragon', 'Type 2_Electric', 'Type 2_Fairy', 'Type 2_Fighting',\n",
        "              'Type 2_Fire', 'Type 2_Flying', 'Type 2_Ghost', 'Type 2_Grass',\n",
        "              'Type 2_Ground', 'Type 2_Ice', 'Type 2_Normal', 'Type 2_Poison',\n",
        "              'Type 2_Psychic', 'Type 2_Rock', 'Type 2_Steel', 'Type 2_Water']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "pokemon_data[features_to_normalize] = \\\n",
        "    scaler.fit_transform(pokemon_data[features_to_normalize])\n",
        "\n",
        "\n",
        "pokemon_data = pd.get_dummies(pokemon_data, columns=['Type 1', 'Type 2'])\n",
        "pokemon_data[features_else] = \\\n",
        "    pokemon_data[features_else].astype(int)\n",
        "\n",
        "hp_weight = 5.0\n",
        "pokemon_data['HP'] *= hp_weight\n",
        "\n",
        "pokemon_data['Legendary'] = pokemon_data['Legendary'].astype(int)\n",
        "pokemon_data['total_stat'] = pokemon_data[features_to_normalize].sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbpDGPs0rY8H"
      },
      "outputs": [],
      "source": [
        "# Split combats data into train and test\n",
        "train_combats, test_combats = train_test_split(combats_data, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# Extract unique vertex values from train_combats and test_combats\n",
        "train_vertices = set(train_combats['First_pokemon']).union(set(train_combats['Second_pokemon']))\n",
        "test_vertices = set(test_combats['First_pokemon']).union(set(test_combats['Second_pokemon']))\n",
        "\n",
        "# Split pokemon data into train and test based on the vertices\n",
        "train_pokemon = pokemon_data[pokemon_data['#'].isin(train_vertices)]\n",
        "test_pokemon = pokemon_data[pokemon_data['#'].isin(test_vertices)]\n",
        "\n",
        "# Decode vertex values back to original values if needed\n",
        "train_pokemon['#'] = label_encoder.inverse_transform(train_pokemon['#'])\n",
        "test_pokemon['#'] = label_encoder.inverse_transform(test_pokemon['#'])\n",
        "\n",
        "# Set \"#\" as index for train_pokemon and test_pokemon dataframes\n",
        "train_pokemon.set_index('#', inplace=True)\n",
        "test_pokemon.set_index('#', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gjzSj-q6rY8H"
      },
      "outputs": [],
      "source": [
        "features = ['total_stat']+features_to_normalize + features_else\n",
        "\n",
        "X_data = pokemon_data[features].values\n",
        "X_data = torch.tensor(X_data, dtype=torch.float)\n",
        "\n",
        "# for train dataset\n",
        "X_train = train_pokemon[features].values\n",
        "X_train = torch.tensor(X_train, dtype=torch.float)\n",
        "edges_train = []\n",
        "neg_edge_index_train = []\n",
        "\n",
        "for _, row in train_combats.iterrows():\n",
        "    first_pokemon = row['First_pokemon']\n",
        "    second_pokemon = row['Second_pokemon']\n",
        "    winner = row['Winner']\n",
        "\n",
        "    if first_pokemon == winner:\n",
        "      edges_train.append((second_pokemon, first_pokemon))\n",
        "      neg_edge_index_train.append((first_pokemon, second_pokemon))\n",
        "\n",
        "    else:\n",
        "      edges_train.append((first_pokemon, second_pokemon))\n",
        "      neg_edge_index_train.append((second_pokemon, first_pokemon))\n",
        "\n",
        "neg_edge_index_train = torch.tensor(neg_edge_index_train, dtype=torch.long).t()\n",
        "edge_index_train = torch.tensor(edges_train, dtype=torch.long).t()\n",
        "\n",
        "data_train = Data(x=X_data, edge_index=edge_index_train, neg_edge_index = neg_edge_index_train)\n",
        "train_loader = DataLoader([data_train], batch_size=1, shuffle=True)\n",
        "\n",
        "# for test dataset\n",
        "X_test = test_pokemon[features].values\n",
        "X_test = torch.tensor(X_test, dtype=torch.float)\n",
        "edges_test = []\n",
        "neg_edge_index_test = []\n",
        "\n",
        "for _, row in test_combats.iterrows():\n",
        "    first_pokemon = row['First_pokemon']\n",
        "    second_pokemon = row['Second_pokemon']\n",
        "    winner = row['Winner']\n",
        "\n",
        "    if first_pokemon == winner:\n",
        "      edges_test.append((second_pokemon, first_pokemon))\n",
        "      neg_edge_index_test.append((first_pokemon, second_pokemon))\n",
        "\n",
        "    else:\n",
        "      edges_test.append((first_pokemon, second_pokemon))\n",
        "      neg_edge_index_test.append((second_pokemon, first_pokemon))\n",
        "\n",
        "edge_index_test = torch.tensor(edges_test, dtype=torch.long).t()\n",
        "neg_edge_index_test = torch.tensor(neg_edge_index_test, dtype=torch.long).t()\n",
        "\n",
        "data_test = Data(x=X_data, edge_index=edge_index_test, neg_edge_index= neg_edge_index_test)\n",
        "test_loader = DataLoader([data_test], batch_size=1, shuffle=False)\n",
        "\n",
        "# for total data\n",
        "edge = edges_train\n",
        "edge.extend(edges_test)\n",
        "edge_index = torch.tensor(edge, dtype=torch.long).t()\n",
        "\n",
        "data_total = Data(x=X_data, edge_index = edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4a2j3ZVCP3D"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bXIEAye8CP3D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# GCN and GraphSage\n",
        "class GraphSageLayer(nn.Module):\n",
        "    def __init__(self, dim_in: int, dim_out: int, agg_type: str):\n",
        "        super(GraphSageLayer, self).__init__()\n",
        "        self.dim_in = dim_in\n",
        "        self.dim_out = dim_out\n",
        "        self.agg_type = agg_type\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "        if self.agg_type == 'gcn':\n",
        "            self.weight = nn.Linear(self.dim_in, self.dim_out, bias=False)\n",
        "            self.bias = nn.Linear(self.dim_in, self.dim_out, bias=False)\n",
        "\n",
        "        elif self.agg_type == 'mean':\n",
        "            self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False)\n",
        "\n",
        "        elif self.agg_type == 'maxpool':\n",
        "            self.linear_pool = nn.Linear(self.dim_in, self.dim_in, bias=True)\n",
        "            self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False)\n",
        "\n",
        "        else:\n",
        "            raise RuntimeError(f\"Unknown aggregation type: {self.agg_type}\")\n",
        "\n",
        "    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n",
        "        if self.agg_type == 'gcn':\n",
        "            feat_h = feat[edge[0]]\n",
        "            idx_t = edge[1]\n",
        "            agg_neighbor = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n",
        "            agg_neighbor = agg_neighbor.index_add_(0, idx_t, feat_h)\n",
        "            degree = torch.bincount(idx_t, minlength=feat.size(0)).unsqueeze(1).to(feat.device)\n",
        "            inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree)\n",
        "            feat_agg = agg_neighbor * inv_degree\n",
        "            out = F.normalize(self.act(self.weight(feat_agg) + self.bias(feat)), 2, -1)\n",
        "\n",
        "        elif self.agg_type == 'mean':\n",
        "            feat_h = feat[edge[0]]\n",
        "            idx_t = edge[1]\n",
        "            agg_neighbor = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n",
        "            agg_neighbor = agg_neighbor.index_add_(0, idx_t, feat_h)\n",
        "            degree = torch.bincount(idx_t, minlength=feat.size(0)).unsqueeze(1).to(feat.device)\n",
        "            inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree)\n",
        "            feat_agg = agg_neighbor * inv_degree\n",
        "            out = F.normalize(self.act(self.weight(torch.cat((feat_agg, feat), 1))), 2, -1)\n",
        "\n",
        "        elif self.agg_type == 'maxpool':\n",
        "            feat = self.act(self.linear_pool(feat))\n",
        "            feat_h = feat[edge[0]]\n",
        "            idx_t = edge[1]\n",
        "            scatter_idx = idx_t.unsqueeze(-1).repeat(1, feat.size(1))\n",
        "            feat_agg = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n",
        "            feat_agg = feat_agg.scatter_reduce(0, scatter_idx, feat_h, reduce='amax', include_self=False)\n",
        "            out = F.normalize(self.act(self.weight(torch.cat((feat_agg, feat), 1))), 2, -1)\n",
        "\n",
        "        else:\n",
        "            raise RuntimeError(f\"Unknown aggregation type: {self.agg_type}\")\n",
        "\n",
        "        return out\n",
        "\n",
        "class GraphSage(nn.Module):\n",
        "    def __init__(self, num_layers: int, dim_in: int, dim_hidden: int, dim_out: int, agg_type: str):\n",
        "        super(GraphSage, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.dim_in = dim_in\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.dim_out = dim_out\n",
        "        self.agg_type = agg_type\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for l in range(num_layers):\n",
        "            self.layers.append(GraphSageLayer(self.dim_in if l == 0 else self.dim_hidden, self.dim_hidden, agg_type))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2 * self.dim_hidden, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n",
        "        x_in = feat\n",
        "        for layer in self.layers:\n",
        "            x_out = layer(x_in, edge)\n",
        "            x_in = x_out\n",
        "        return x_out\n",
        "\n",
        "    def predict(self, head: torch.Tensor, tail: torch.Tensor) -> torch.Tensor:\n",
        "        head_tail = torch.cat([head, tail], dim=-1)\n",
        "        score = self.classifier(head_tail)\n",
        "        return score\n",
        "\n",
        "# GAT\n",
        "# GAT\n",
        "class GATLayer(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int, dropout: float = 0.5, alpha: float = 0.2) -> None:\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.W = nn.Parameter(torch.empty(size=(in_dim, out_dim)))\n",
        "        nn.init.xavier_uniform_(self.W.data)\n",
        "        self.a = nn.Parameter(torch.empty(size=(2 * out_dim, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(negative_slope=self.alpha)\n",
        "        self.batch_norm = nn.BatchNorm1d(out_dim)\n",
        "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
        "        self.residual = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, feat: torch.Tensor, edges: torch.Tensor) -> torch.Tensor:\n",
        "        message = feat @ self.W\n",
        "        attn_src = message @ self.a[:self.out_dim, :]\n",
        "        attn_dst = message @ self.a[self.out_dim:, :]\n",
        "\n",
        "        src, dst = edges\n",
        "        attn_scores = self.leakyrelu(attn_src[src] + attn_dst[dst])\n",
        "        attn_scores = attn_scores - attn_scores.max()  # for stabilization of softmax\n",
        "\n",
        "        # Edge softmax\n",
        "        exp_attn_scores = attn_scores.exp()\n",
        "        exp_sum = torch.zeros((feat.shape[0], 1), device=feat.device).scatter_add_(\n",
        "            dim=0,\n",
        "            index=dst.unsqueeze(1),\n",
        "            src=exp_attn_scores\n",
        "        ) + 1e-10  # Prevent division by zero\n",
        "\n",
        "        attn_coeffs = exp_attn_scores / exp_sum[dst]\n",
        "        attn_coeffs = self.dropout_layer(attn_coeffs)\n",
        "\n",
        "        # Weighted aggregation\n",
        "        out = torch.zeros_like(message, device=feat.device).scatter_add_(\n",
        "            dim=0,\n",
        "            index=dst.unsqueeze(1).expand(-1, self.out_dim),\n",
        "            src=message[src] * attn_coeffs\n",
        "        )\n",
        "        out += self.residual(feat)  # Residual connection\n",
        "        out = self.batch_norm(out)\n",
        "        return out\n",
        "\n",
        "#GAT\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, dim_in: int, dim_hidden: int, dim_out: int, dropout: float = 0.5, alpha: float = 0.2, num_heads: int = 8) -> None:\n",
        "        super(GAT, self).__init__()\n",
        "        self.dim_in = dim_in\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.dim_out = dim_out\n",
        "        self.dropout = dropout\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attn_heads1 = nn.ModuleList()\n",
        "        for _ in range(num_heads):\n",
        "            self.attn_heads1.append(\n",
        "                GATLayer(self.dim_in, self.dim_hidden, dropout=dropout, alpha=alpha)\n",
        "            )\n",
        "\n",
        "        self.attn_heads2 = nn.ModuleList()\n",
        "        for _ in range(num_heads):\n",
        "            self.attn_heads2.append(\n",
        "                GATLayer(self.dim_hidden * num_heads, self.dim_hidden, dropout=dropout, alpha=alpha)\n",
        "            )\n",
        "\n",
        "        self.output_layer = GATLayer(self.dim_hidden * num_heads, self.dim_out, dropout=dropout, alpha=alpha)\n",
        "        self.residual = nn.Linear(self.dim_in, self.dim_out)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2 * self.dim_out, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n",
        "        x_in = feat\n",
        "\n",
        "        multi_head_out1 = []\n",
        "        for attn_head in self.attn_heads1:\n",
        "            multi_head_out1.append(attn_head(x_in, edge))\n",
        "        x_out1 = torch.cat(multi_head_out1, dim=-1)\n",
        "\n",
        "        multi_head_out2 = []\n",
        "        for attn_head in self.attn_heads2:\n",
        "            multi_head_out2.append(attn_head(x_out1, edge))\n",
        "        x_out2 = torch.cat(multi_head_out2, dim=-1)\n",
        "\n",
        "        x_out = self.output_layer(x_out2, edge)\n",
        "        x_out += self.residual(x_in)  # Residual connection\n",
        "        return x_out\n",
        "\n",
        "    def predict(self, head: torch.Tensor, tail: torch.Tensor) -> torch.Tensor:\n",
        "        head_tail = torch.cat([head, tail], dim=-1)\n",
        "        score = self.classifier(head_tail)\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIWFHRYrY8I"
      },
      "source": [
        "# Define Train, Test, Predict Frameworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MlzM70M3rY8I"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "\n",
        "        pos_edge_index = data.edge_index\n",
        "        neg_edge_index = data.neg_edge_index\n",
        "\n",
        "        pos_head = out[pos_edge_index[0]]\n",
        "        pos_tail = out[pos_edge_index[1]]\n",
        "        neg_head = out[neg_edge_index[0]]\n",
        "        neg_tail = out[neg_edge_index[1]]\n",
        "\n",
        "        pos_pred = model.predict(pos_head, pos_tail)\n",
        "        neg_pred = model.predict(neg_head, neg_tail)\n",
        "\n",
        "        pos_loss = F.binary_cross_entropy_with_logits(pos_pred, torch.ones_like(pos_pred))\n",
        "        neg_loss = F.binary_cross_entropy_with_logits(neg_pred, torch.zeros_like(neg_pred))\n",
        "        loss = pos_loss + neg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def test(model, loader, device):\n",
        "    model.eval()\n",
        "    auc = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data.x, data.edge_index)\n",
        "\n",
        "            pos_edge_index = data.edge_index\n",
        "            neg_edge_index = data.neg_edge_index\n",
        "\n",
        "            pos_head = out[pos_edge_index[0]]\n",
        "            pos_tail = out[pos_edge_index[1]]\n",
        "            neg_head = out[neg_edge_index[0]]\n",
        "            neg_tail = out[neg_edge_index[1]]\n",
        "\n",
        "            pos_pred = model.predict(pos_head, pos_tail)\n",
        "            neg_pred = model.predict(neg_head, neg_tail)\n",
        "            preds = torch.cat([pos_pred, neg_pred])\n",
        "\n",
        "            pos_labels = torch.ones_like(pos_pred)\n",
        "            neg_labels = torch.zeros_like(neg_pred)\n",
        "            labels = torch.cat([pos_labels, neg_labels])\n",
        "\n",
        "            auc += roc_auc_score(labels.cpu(), preds.cpu())\n",
        "\n",
        "    return auc / len(loader)\n",
        "\n",
        "def predict(model, head, tail, data, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index)\n",
        "        head_feature = out[head]\n",
        "        tail_feature = out[tail]\n",
        "        score = model.predict(head_feature, tail_feature)\n",
        "        reverse_score = model.predict(tail_feature, head_feature)\n",
        "        return torch.sigmoid(score).item(), torch.sigmoid(reverse_score).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVG6f97PrY8I"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sp0NfQAgrY8I"
      },
      "outputs": [],
      "source": [
        "# Choose model from [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]\n",
        "def train_model(epoch, model_type, data_train, data_test, train_loader, test_loader, device):\n",
        "    EPOCH = epoch\n",
        "    MODEL = model_type\n",
        "\n",
        "    if MODEL == \"GCN\":\n",
        "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"gcn\")\n",
        "    elif MODEL == \"GraphSage_mean\":\n",
        "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"mean\")\n",
        "    elif MODEL == \"GraphSage_maxpool\":\n",
        "        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"maxpool\")\n",
        "    elif MODEL == \"GAT\":\n",
        "        model = GAT(dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, dropout = 0.5, alpha = 0.2, num_heads = 8)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    data_train = data_train.to(device)\n",
        "    data_test = data_test.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    patience = 3 # for early stopping\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        loss = train(model, optimizer, train_loader, device)\n",
        "        if epoch % 10 == 0:\n",
        "            test_auc = test(model, test_loader, device)\n",
        "            train_auc = test(model, train_loader, device)\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Test AUC: {test_auc:.4f}')\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve == patience:\n",
        "                    print(\"Early stopping triggered\")\n",
        "                    break\n",
        "    return model\n",
        "\n",
        "# calculate prediction accuracy\n",
        "def test_model(model, data_total, data_test, device):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    head_list, tail_list = data_test.edge_index\n",
        "    head_list = list(head_list)\n",
        "    tail_list = list(tail_list)\n",
        "\n",
        "    pos = 0\n",
        "    for idx in range(len(head_list)):\n",
        "        head = head_list[idx]\n",
        "        tail = tail_list[idx]\n",
        "        prediction, reverse_prediction = predict(model, head, tail, data_total, device)\n",
        "        if prediction > reverse_prediction:\n",
        "            pos += 1\n",
        "\n",
        "    print(f\"Prediction accuracy: {pos/len(head_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "y9-kgvvsrY8I"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# select model from model_types\n",
        "model_types = [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]\n",
        "epoch = 600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwIlFFS0rY8I",
        "outputId": "5f6cb789-c797-40bf-df2f-7e22f133cd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 1.3873, Train AUC: 0.6845, Test AUC: 0.6416\n",
            "Epoch: 010, Loss: 1.0512, Train AUC: 0.8673, Test AUC: 0.8499\n",
            "Epoch: 020, Loss: 0.7299, Train AUC: 0.9223, Test AUC: 0.8949\n",
            "Epoch: 030, Loss: 0.6728, Train AUC: 0.9323, Test AUC: 0.9144\n",
            "Epoch: 040, Loss: 0.6307, Train AUC: 0.9392, Test AUC: 0.9261\n",
            "Epoch: 050, Loss: 0.6054, Train AUC: 0.9517, Test AUC: 0.9390\n",
            "Epoch: 060, Loss: 0.5407, Train AUC: 0.9599, Test AUC: 0.9445\n",
            "Epoch: 070, Loss: 0.4951, Train AUC: 0.9646, Test AUC: 0.9507\n",
            "Epoch: 080, Loss: 0.4620, Train AUC: 0.9685, Test AUC: 0.9545\n",
            "Epoch: 090, Loss: 0.4298, Train AUC: 0.9720, Test AUC: 0.9566\n",
            "Epoch: 100, Loss: 0.4080, Train AUC: 0.9738, Test AUC: 0.9573\n",
            "Epoch: 110, Loss: 0.3877, Train AUC: 0.9759, Test AUC: 0.9584\n",
            "Epoch: 120, Loss: 0.3682, Train AUC: 0.9787, Test AUC: 0.9576\n",
            "Epoch: 130, Loss: 0.3689, Train AUC: 0.9810, Test AUC: 0.9529\n",
            "Epoch: 140, Loss: 0.3569, Train AUC: 0.9801, Test AUC: 0.9597\n",
            "Epoch: 150, Loss: 0.3946, Train AUC: 0.9795, Test AUC: 0.9599\n",
            "Epoch: 160, Loss: 0.3479, Train AUC: 0.9814, Test AUC: 0.9591\n",
            "Epoch: 170, Loss: 0.3337, Train AUC: 0.9830, Test AUC: 0.9592\n",
            "Epoch: 180, Loss: 0.3238, Train AUC: 0.9842, Test AUC: 0.9579\n",
            "Epoch: 190, Loss: 0.3172, Train AUC: 0.9846, Test AUC: 0.9593\n",
            "Epoch: 200, Loss: 0.3164, Train AUC: 0.9853, Test AUC: 0.9582\n",
            "Epoch: 210, Loss: 0.3261, Train AUC: 0.9856, Test AUC: 0.9574\n",
            "Epoch: 220, Loss: 0.3200, Train AUC: 0.9860, Test AUC: 0.9586\n",
            "Epoch: 230, Loss: 0.3033, Train AUC: 0.9860, Test AUC: 0.9595\n",
            "Epoch: 240, Loss: 0.2943, Train AUC: 0.9870, Test AUC: 0.9576\n",
            "Epoch: 250, Loss: 0.2901, Train AUC: 0.9871, Test AUC: 0.9557\n",
            "Epoch: 260, Loss: 0.2854, Train AUC: 0.9876, Test AUC: 0.9572\n",
            "Epoch: 270, Loss: 0.2808, Train AUC: 0.9882, Test AUC: 0.9565\n",
            "Epoch: 280, Loss: 0.2757, Train AUC: 0.9887, Test AUC: 0.9564\n",
            "Epoch: 290, Loss: 0.2741, Train AUC: 0.9884, Test AUC: 0.9603\n",
            "Epoch: 300, Loss: 0.2705, Train AUC: 0.9890, Test AUC: 0.9592\n",
            "Epoch: 310, Loss: 0.2654, Train AUC: 0.9896, Test AUC: 0.9595\n",
            "Epoch: 320, Loss: 0.2597, Train AUC: 0.9902, Test AUC: 0.9562\n",
            "Epoch: 330, Loss: 0.2566, Train AUC: 0.9902, Test AUC: 0.9573\n",
            "Epoch: 340, Loss: 0.2503, Train AUC: 0.9909, Test AUC: 0.9577\n",
            "Epoch: 350, Loss: 0.2508, Train AUC: 0.9908, Test AUC: 0.9546\n",
            "Epoch: 360, Loss: 0.2544, Train AUC: 0.9911, Test AUC: 0.9556\n",
            "Epoch: 370, Loss: 0.2366, Train AUC: 0.9916, Test AUC: 0.9600\n",
            "Epoch: 380, Loss: 0.2502, Train AUC: 0.9915, Test AUC: 0.9584\n",
            "Epoch: 390, Loss: 0.2317, Train AUC: 0.9922, Test AUC: 0.9562\n",
            "Epoch: 400, Loss: 0.2248, Train AUC: 0.9927, Test AUC: 0.9591\n",
            "Epoch: 410, Loss: 0.2197, Train AUC: 0.9928, Test AUC: 0.9586\n",
            "Epoch: 420, Loss: 0.2355, Train AUC: 0.9924, Test AUC: 0.9556\n",
            "Epoch: 430, Loss: 0.2190, Train AUC: 0.9933, Test AUC: 0.9574\n",
            "Epoch: 440, Loss: 0.2107, Train AUC: 0.9937, Test AUC: 0.9569\n",
            "Epoch: 450, Loss: 0.2104, Train AUC: 0.9936, Test AUC: 0.9540\n",
            "Epoch: 460, Loss: 0.2052, Train AUC: 0.9941, Test AUC: 0.9543\n",
            "Epoch: 470, Loss: 0.2079, Train AUC: 0.9929, Test AUC: 0.9520\n",
            "Epoch: 480, Loss: 0.2112, Train AUC: 0.9935, Test AUC: 0.9570\n",
            "Epoch: 490, Loss: 0.1946, Train AUC: 0.9945, Test AUC: 0.9565\n",
            "Epoch: 500, Loss: 0.1922, Train AUC: 0.9948, Test AUC: 0.9546\n",
            "Epoch: 510, Loss: 0.1872, Train AUC: 0.9952, Test AUC: 0.9566\n",
            "Epoch: 520, Loss: 0.1802, Train AUC: 0.9953, Test AUC: 0.9559\n",
            "Epoch: 530, Loss: 0.1960, Train AUC: 0.9945, Test AUC: 0.9569\n",
            "Epoch: 540, Loss: 0.1775, Train AUC: 0.9953, Test AUC: 0.9534\n",
            "Epoch: 550, Loss: 0.1729, Train AUC: 0.9959, Test AUC: 0.9537\n",
            "Epoch: 560, Loss: 0.1741, Train AUC: 0.9960, Test AUC: 0.9532\n",
            "Epoch: 570, Loss: 0.1694, Train AUC: 0.9961, Test AUC: 0.9563\n",
            "Epoch: 580, Loss: 0.1621, Train AUC: 0.9963, Test AUC: 0.9550\n",
            "Epoch: 590, Loss: 0.1711, Train AUC: 0.9958, Test AUC: 0.9585\n",
            "Prediction accuracy: 0.9325\n"
          ]
        }
      ],
      "source": [
        "gcn_model = train_model(epoch, \"GCN\", data_train, data_test, train_loader, test_loader, device)\n",
        "test_model(gcn_model, data_total, data_test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaBx2nb6rY8I",
        "outputId": "8ae1abf0-0ab5-49a5-d232-fdbf87ccba36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 1.3859, Train AUC: 0.7252, Test AUC: 0.6540\n",
            "Epoch: 010, Loss: 0.9765, Train AUC: 0.8708, Test AUC: 0.8473\n",
            "Epoch: 020, Loss: 0.7504, Train AUC: 0.9211, Test AUC: 0.8919\n",
            "Epoch: 030, Loss: 0.6859, Train AUC: 0.9302, Test AUC: 0.9139\n",
            "Epoch: 040, Loss: 0.6569, Train AUC: 0.9342, Test AUC: 0.9228\n",
            "Epoch: 050, Loss: 0.6176, Train AUC: 0.9432, Test AUC: 0.9334\n",
            "Epoch: 060, Loss: 0.5911, Train AUC: 0.9534, Test AUC: 0.9442\n",
            "Epoch: 070, Loss: 0.5305, Train AUC: 0.9606, Test AUC: 0.9479\n",
            "Epoch: 080, Loss: 0.5025, Train AUC: 0.9640, Test AUC: 0.9519\n",
            "Epoch: 090, Loss: 0.4755, Train AUC: 0.9677, Test AUC: 0.9543\n",
            "Epoch: 100, Loss: 0.4649, Train AUC: 0.9656, Test AUC: 0.9580\n",
            "Epoch: 110, Loss: 0.4750, Train AUC: 0.9667, Test AUC: 0.9577\n",
            "Epoch: 120, Loss: 0.4312, Train AUC: 0.9732, Test AUC: 0.9572\n",
            "Epoch: 130, Loss: 0.4049, Train AUC: 0.9756, Test AUC: 0.9605\n",
            "Epoch: 140, Loss: 0.3858, Train AUC: 0.9776, Test AUC: 0.9618\n",
            "Epoch: 150, Loss: 0.3763, Train AUC: 0.9791, Test AUC: 0.9621\n",
            "Epoch: 160, Loss: 0.3658, Train AUC: 0.9805, Test AUC: 0.9632\n",
            "Epoch: 170, Loss: 0.3477, Train AUC: 0.9815, Test AUC: 0.9631\n",
            "Epoch: 180, Loss: 0.3406, Train AUC: 0.9823, Test AUC: 0.9607\n",
            "Epoch: 190, Loss: 0.3344, Train AUC: 0.9831, Test AUC: 0.9608\n",
            "Epoch: 200, Loss: 0.3264, Train AUC: 0.9839, Test AUC: 0.9618\n",
            "Epoch: 210, Loss: 0.3217, Train AUC: 0.9840, Test AUC: 0.9648\n",
            "Epoch: 220, Loss: 0.3160, Train AUC: 0.9849, Test AUC: 0.9617\n",
            "Epoch: 230, Loss: 0.3165, Train AUC: 0.9848, Test AUC: 0.9647\n",
            "Epoch: 240, Loss: 0.3077, Train AUC: 0.9858, Test AUC: 0.9616\n",
            "Epoch: 250, Loss: 0.3016, Train AUC: 0.9864, Test AUC: 0.9623\n",
            "Epoch: 260, Loss: 0.2925, Train AUC: 0.9869, Test AUC: 0.9603\n",
            "Epoch: 270, Loss: 0.3099, Train AUC: 0.9857, Test AUC: 0.9645\n",
            "Epoch: 280, Loss: 0.2972, Train AUC: 0.9872, Test AUC: 0.9630\n",
            "Epoch: 290, Loss: 0.2858, Train AUC: 0.9876, Test AUC: 0.9613\n",
            "Epoch: 300, Loss: 0.2813, Train AUC: 0.9880, Test AUC: 0.9635\n",
            "Epoch: 310, Loss: 0.2790, Train AUC: 0.9878, Test AUC: 0.9622\n",
            "Epoch: 320, Loss: 0.2708, Train AUC: 0.9891, Test AUC: 0.9619\n",
            "Epoch: 330, Loss: 0.2658, Train AUC: 0.9895, Test AUC: 0.9611\n",
            "Epoch: 340, Loss: 0.2648, Train AUC: 0.9888, Test AUC: 0.9604\n",
            "Epoch: 350, Loss: 0.2620, Train AUC: 0.9895, Test AUC: 0.9605\n",
            "Epoch: 360, Loss: 0.2583, Train AUC: 0.9899, Test AUC: 0.9616\n",
            "Epoch: 370, Loss: 0.2551, Train AUC: 0.9903, Test AUC: 0.9597\n",
            "Epoch: 380, Loss: 0.2497, Train AUC: 0.9905, Test AUC: 0.9589\n",
            "Epoch: 390, Loss: 0.2475, Train AUC: 0.9902, Test AUC: 0.9606\n",
            "Epoch: 400, Loss: 0.2513, Train AUC: 0.9901, Test AUC: 0.9611\n",
            "Epoch: 410, Loss: 0.2527, Train AUC: 0.9904, Test AUC: 0.9576\n",
            "Epoch: 420, Loss: 0.2416, Train AUC: 0.9914, Test AUC: 0.9593\n",
            "Epoch: 430, Loss: 0.2332, Train AUC: 0.9920, Test AUC: 0.9573\n",
            "Epoch: 440, Loss: 0.2654, Train AUC: 0.9902, Test AUC: 0.9503\n",
            "Epoch: 450, Loss: 0.2688, Train AUC: 0.9905, Test AUC: 0.9605\n",
            "Epoch: 460, Loss: 0.2387, Train AUC: 0.9916, Test AUC: 0.9565\n",
            "Early stopping triggered\n",
            "Prediction accuracy: 0.9323\n"
          ]
        }
      ],
      "source": [
        "graphsage_mean_model = train_model(epoch, \"GraphSage_mean\", data_train, data_test, train_loader, test_loader, device)\n",
        "test_model(graphsage_mean_model, data_total, data_test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_0EABqCrY8I",
        "outputId": "dd5aa30a-5593-406c-97af-fa26505b1ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 1.3869, Train AUC: 0.7076, Test AUC: 0.6965\n",
            "Epoch: 010, Loss: 1.2976, Train AUC: 0.8522, Test AUC: 0.8295\n",
            "Epoch: 020, Loss: 0.8342, Train AUC: 0.9065, Test AUC: 0.8887\n",
            "Epoch: 030, Loss: 0.7085, Train AUC: 0.9263, Test AUC: 0.9199\n",
            "Epoch: 040, Loss: 0.6564, Train AUC: 0.9339, Test AUC: 0.9268\n",
            "Epoch: 050, Loss: 0.6341, Train AUC: 0.9366, Test AUC: 0.9292\n",
            "Epoch: 060, Loss: 0.6090, Train AUC: 0.9422, Test AUC: 0.9348\n",
            "Epoch: 070, Loss: 0.5889, Train AUC: 0.9468, Test AUC: 0.9321\n",
            "Epoch: 080, Loss: 0.5607, Train AUC: 0.9535, Test AUC: 0.9353\n",
            "Epoch: 090, Loss: 0.5181, Train AUC: 0.9614, Test AUC: 0.9431\n",
            "Epoch: 100, Loss: 0.4776, Train AUC: 0.9669, Test AUC: 0.9480\n",
            "Epoch: 110, Loss: 0.5417, Train AUC: 0.9543, Test AUC: 0.9499\n",
            "Epoch: 120, Loss: 0.4762, Train AUC: 0.9661, Test AUC: 0.9483\n",
            "Epoch: 130, Loss: 0.4354, Train AUC: 0.9714, Test AUC: 0.9536\n",
            "Epoch: 140, Loss: 0.4103, Train AUC: 0.9746, Test AUC: 0.9579\n",
            "Epoch: 150, Loss: 0.3998, Train AUC: 0.9767, Test AUC: 0.9608\n",
            "Epoch: 160, Loss: 0.3791, Train AUC: 0.9782, Test AUC: 0.9621\n",
            "Epoch: 170, Loss: 0.3708, Train AUC: 0.9778, Test AUC: 0.9597\n",
            "Epoch: 180, Loss: 0.4551, Train AUC: 0.9746, Test AUC: 0.9613\n",
            "Epoch: 190, Loss: 0.3868, Train AUC: 0.9783, Test AUC: 0.9638\n",
            "Epoch: 200, Loss: 0.3628, Train AUC: 0.9801, Test AUC: 0.9648\n",
            "Epoch: 210, Loss: 0.3503, Train AUC: 0.9812, Test AUC: 0.9655\n",
            "Epoch: 220, Loss: 0.3423, Train AUC: 0.9821, Test AUC: 0.9652\n",
            "Epoch: 230, Loss: 0.3364, Train AUC: 0.9827, Test AUC: 0.9659\n",
            "Epoch: 240, Loss: 0.3328, Train AUC: 0.9828, Test AUC: 0.9647\n",
            "Epoch: 250, Loss: 0.3291, Train AUC: 0.9837, Test AUC: 0.9665\n",
            "Epoch: 260, Loss: 0.3217, Train AUC: 0.9842, Test AUC: 0.9657\n",
            "Epoch: 270, Loss: 0.3194, Train AUC: 0.9839, Test AUC: 0.9653\n",
            "Epoch: 280, Loss: 0.3150, Train AUC: 0.9846, Test AUC: 0.9657\n",
            "Epoch: 290, Loss: 0.3118, Train AUC: 0.9852, Test AUC: 0.9670\n",
            "Epoch: 300, Loss: 0.3232, Train AUC: 0.9855, Test AUC: 0.9669\n",
            "Epoch: 310, Loss: 0.3149, Train AUC: 0.9848, Test AUC: 0.9675\n",
            "Epoch: 320, Loss: 0.3100, Train AUC: 0.9853, Test AUC: 0.9680\n",
            "Epoch: 330, Loss: 0.3038, Train AUC: 0.9861, Test AUC: 0.9680\n",
            "Epoch: 340, Loss: 0.2990, Train AUC: 0.9863, Test AUC: 0.9678\n",
            "Epoch: 350, Loss: 0.3018, Train AUC: 0.9866, Test AUC: 0.9683\n",
            "Epoch: 360, Loss: 0.2941, Train AUC: 0.9869, Test AUC: 0.9689\n",
            "Epoch: 370, Loss: 0.2930, Train AUC: 0.9869, Test AUC: 0.9692\n",
            "Epoch: 380, Loss: 0.2945, Train AUC: 0.9865, Test AUC: 0.9682\n",
            "Epoch: 390, Loss: 0.2952, Train AUC: 0.9868, Test AUC: 0.9681\n",
            "Epoch: 400, Loss: 0.2914, Train AUC: 0.9875, Test AUC: 0.9686\n",
            "Epoch: 410, Loss: 0.2965, Train AUC: 0.9853, Test AUC: 0.9699\n",
            "Epoch: 420, Loss: 0.3123, Train AUC: 0.9852, Test AUC: 0.9692\n",
            "Epoch: 430, Loss: 0.2935, Train AUC: 0.9869, Test AUC: 0.9695\n",
            "Early stopping triggered\n",
            "Prediction accuracy: 0.9266\n"
          ]
        }
      ],
      "source": [
        "graphsage_max_model = train_model(epoch, \"GraphSage_maxpool\", data_train, data_test, train_loader, test_loader, device)\n",
        "test_model(graphsage_max_model, data_total, data_test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY4baGg0rY8I",
        "outputId": "ce931d26-a307-4fd3-fdc7-89c04ac9ad4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 1.4020, Train AUC: 0.5441, Test AUC: 0.5002\n",
            "Epoch: 010, Loss: 0.8676, Train AUC: 0.8970, Test AUC: 0.8880\n",
            "Epoch: 020, Loss: 0.7232, Train AUC: 0.9240, Test AUC: 0.9127\n",
            "Epoch: 030, Loss: 0.6173, Train AUC: 0.9369, Test AUC: 0.9329\n",
            "Epoch: 040, Loss: 0.5306, Train AUC: 0.9460, Test AUC: 0.9441\n",
            "Epoch: 050, Loss: 0.4628, Train AUC: 0.9628, Test AUC: 0.9610\n",
            "Epoch: 060, Loss: 0.4120, Train AUC: 0.9742, Test AUC: 0.9718\n",
            "Epoch: 070, Loss: 0.3840, Train AUC: 0.9767, Test AUC: 0.9737\n",
            "Epoch: 080, Loss: 0.3664, Train AUC: 0.9794, Test AUC: 0.9774\n",
            "Epoch: 090, Loss: 0.3654, Train AUC: 0.9802, Test AUC: 0.9785\n",
            "Epoch: 100, Loss: 0.3498, Train AUC: 0.9810, Test AUC: 0.9793\n",
            "Epoch: 110, Loss: 0.3537, Train AUC: 0.9810, Test AUC: 0.9790\n",
            "Epoch: 120, Loss: 0.3445, Train AUC: 0.9821, Test AUC: 0.9798\n",
            "Epoch: 130, Loss: 0.3390, Train AUC: 0.9826, Test AUC: 0.9798\n",
            "Epoch: 140, Loss: 0.3341, Train AUC: 0.9833, Test AUC: 0.9804\n",
            "Epoch: 150, Loss: 0.3293, Train AUC: 0.9837, Test AUC: 0.9812\n",
            "Epoch: 160, Loss: 0.3213, Train AUC: 0.9840, Test AUC: 0.9807\n",
            "Epoch: 170, Loss: 0.3245, Train AUC: 0.9846, Test AUC: 0.9824\n",
            "Epoch: 180, Loss: 0.3190, Train AUC: 0.9855, Test AUC: 0.9826\n",
            "Epoch: 190, Loss: 0.3094, Train AUC: 0.9858, Test AUC: 0.9831\n",
            "Epoch: 200, Loss: 0.3061, Train AUC: 0.9864, Test AUC: 0.9836\n",
            "Epoch: 210, Loss: 0.3017, Train AUC: 0.9867, Test AUC: 0.9842\n",
            "Epoch: 220, Loss: 0.2960, Train AUC: 0.9870, Test AUC: 0.9848\n",
            "Epoch: 230, Loss: 0.2931, Train AUC: 0.9873, Test AUC: 0.9848\n",
            "Epoch: 240, Loss: 0.2893, Train AUC: 0.9878, Test AUC: 0.9856\n",
            "Epoch: 250, Loss: 0.2857, Train AUC: 0.9879, Test AUC: 0.9854\n",
            "Epoch: 260, Loss: 0.2823, Train AUC: 0.9885, Test AUC: 0.9860\n",
            "Epoch: 270, Loss: 0.2858, Train AUC: 0.9884, Test AUC: 0.9859\n",
            "Epoch: 280, Loss: 0.2791, Train AUC: 0.9881, Test AUC: 0.9854\n",
            "Epoch: 290, Loss: 0.2716, Train AUC: 0.9890, Test AUC: 0.9860\n",
            "Epoch: 300, Loss: 0.2698, Train AUC: 0.9895, Test AUC: 0.9859\n",
            "Epoch: 310, Loss: 0.2744, Train AUC: 0.9898, Test AUC: 0.9858\n",
            "Epoch: 320, Loss: 0.2681, Train AUC: 0.9896, Test AUC: 0.9852\n",
            "Epoch: 330, Loss: 0.2625, Train AUC: 0.9900, Test AUC: 0.9859\n",
            "Epoch: 340, Loss: 0.2597, Train AUC: 0.9903, Test AUC: 0.9858\n",
            "Epoch: 350, Loss: 0.2560, Train AUC: 0.9909, Test AUC: 0.9860\n",
            "Epoch: 360, Loss: 0.2497, Train AUC: 0.9911, Test AUC: 0.9862\n",
            "Epoch: 370, Loss: 0.2440, Train AUC: 0.9914, Test AUC: 0.9868\n",
            "Epoch: 380, Loss: 0.2416, Train AUC: 0.9920, Test AUC: 0.9872\n",
            "Epoch: 390, Loss: 0.2370, Train AUC: 0.9922, Test AUC: 0.9871\n",
            "Epoch: 400, Loss: 0.2403, Train AUC: 0.9923, Test AUC: 0.9874\n",
            "Epoch: 410, Loss: 0.2334, Train AUC: 0.9926, Test AUC: 0.9870\n",
            "Epoch: 420, Loss: 0.2289, Train AUC: 0.9926, Test AUC: 0.9876\n",
            "Epoch: 430, Loss: 0.2313, Train AUC: 0.9922, Test AUC: 0.9863\n",
            "Epoch: 440, Loss: 0.2273, Train AUC: 0.9928, Test AUC: 0.9874\n",
            "Epoch: 450, Loss: 0.2235, Train AUC: 0.9929, Test AUC: 0.9878\n",
            "Epoch: 460, Loss: 0.2189, Train AUC: 0.9927, Test AUC: 0.9880\n",
            "Epoch: 470, Loss: 0.2320, Train AUC: 0.9922, Test AUC: 0.9870\n",
            "Epoch: 480, Loss: 0.3219, Train AUC: 0.9859, Test AUC: 0.9818\n",
            "Epoch: 490, Loss: 0.2302, Train AUC: 0.9876, Test AUC: 0.9801\n",
            "Early stopping triggered\n",
            "Prediction accuracy: 0.9301\n"
          ]
        }
      ],
      "source": [
        "gat_model = train_model(epoch, \"GAT\", data_train, data_test, train_loader, test_loader, device)\n",
        "test_model(gat_model, data_total, data_test, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxMmQRCdCP3E"
      },
      "source": [
        "# Application: 6 vs 6 win strategy (ordering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVgBNRS1CP3E"
      },
      "source": [
        "\n",
        "Implementing an application that dynamically suggests the Pokemon you should send out to win when the order of the opponent's Pokemon appears randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OylBiT6uuuKv"
      },
      "outputs": [],
      "source": [
        "def node_feature_update(winner, loser, data_battle):\n",
        "  \"\"\"\n",
        "  Update the node feature of the winner and loser pokemon after the battle\n",
        "\n",
        "  INPUT\n",
        "  winner: winner pokemon id\n",
        "  loser: loser pokemon id\n",
        "  data_battle: data object for the battle\n",
        "\n",
        "  \"\"\"\n",
        "  damage = sum(data_battle.x[loser][i].item() for i in range(2, 8))\n",
        "  data_battle.x[winner][1] -= damage\n",
        "  data_battle.x[winner][0] = sum(data_battle.x[winner][i].item() for i in range(1, 8))\n",
        "\n",
        "  return data_battle\n",
        "\n",
        "\n",
        "def find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon=None):\n",
        "  \"\"\"\n",
        "  If my_pokemon is None, find the pokemon to fight against the opponent pokemon and return the result.\n",
        "  If there is no pokemon that can win, choose the pokemon with the lowest stats among them and update the node feature\n",
        "  If there are pokemons that can win, choose the pokemon with the lowest probability of winning among them and update the node feature\n",
        "\n",
        "  If my_pokemon is not None, return the result of the fight.\n",
        "\n",
        "  INPUT\n",
        "  model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n",
        "  opponents: list of opponent pokemon id\n",
        "  ours: list of our alive pokemon id\n",
        "  opp_idx: index of the opponent pokemon in the opponents list\n",
        "  data_battle: data object for the battle\n",
        "  my_pokemon: my pokemon that won in previous round. None if we lose.\n",
        "\n",
        "  OUTPUT\n",
        "  win: 1 if we lose, 2 if we win (0: default)\n",
        "  my_pokemon: my pokemon participating in this round / if my_pokemon is not None, then return my_pokemon is None\n",
        "  \"\"\"\n",
        "  win = 0\n",
        "  node1 = opponents[opp_idx]\n",
        "  my_winner_pokemon = [] # (pokemon_id, win_prob) list\n",
        "\n",
        "  # 첫 라운드거나 이전 라운드에서 우리가 패배한 경우 (새로운 my_pokemon을 찾아야 하는 경우)\n",
        "  if my_pokemon==None:\n",
        "    # 남아있는 내 포켓몬들을 다 돌아보면서 승리할 확률이 더 높은 pokemon들을 my_winner_pokemon에 prediction score와 함께 append\n",
        "    for our_idx in range(len(remained_ours)):\n",
        "      node2 = remained_ours[our_idx]\n",
        "      prediction, reverse_prediction = predict(model, node1, node2, data_battle.to(device), device) # 우리 pokemon이 이길 prediction score\n",
        "      if prediction > reverse_prediction:\n",
        "        my_winner_pokemon.append((remained_ours[our_idx], prediction))\n",
        "\n",
        "    if not len(my_winner_pokemon):\n",
        "      # 이길 수 있는 pokemon이 없다면 전체적인 stat이 높은 순서로 정렬하여 가장 약한 pokemon이 나가도록 한다.\n",
        "      sorted_stats_idx = sorted(range(len(remained_ours)), key=lambda i: data_battle.x[remained_ours[i]][0].item())\n",
        "\n",
        "      my_pokemon = remained_ours[sorted_stats_idx[0]] # sorting한 것에서 맨 앞에(stat이 가장 작은) 있는 index의 pokemon을 내보낸다.\n",
        "      win = 1 # we lose\n",
        "    else:\n",
        "      # 이길 수 있는 pokemon이 있다면 -> prob 크기 순서대로 정렬하고 prob 가장 작은 pokemon을 ordering에 추가\n",
        "      my_winner_pokemon = sorted(my_winner_pokemon, key=lambda pokemon_pair: pokemon_pair[1]) # prediction score 값을 토대로 sorting\n",
        "      winner = my_winner_pokemon[0][0]\n",
        "      my_pokemon = winner\n",
        "      win = 2 # we win\n",
        "\n",
        "    return win, my_pokemon\n",
        "\n",
        "  # 이전 라운드에서 우리 포켓몬이 이긴 경우\n",
        "  else:\n",
        "    # opponents[opp_idx]와 my_pokemon의 승부 결과를 return해야 한다.\n",
        "    node2 = my_pokemon\n",
        "    prediction, reverse_prediction = predict(model, node1, node2, data_battle.to(device), device) # 우리 pokemon이 이길 prediction score\n",
        "    if prediction > reverse_prediction:\n",
        "      win = 2 # we win\n",
        "    else:\n",
        "      win = 1\n",
        "    return win, None\n",
        "\n",
        "def search_pokemon_name(pokemon_id):\n",
        "  for i in range(len(pokemon_data)):\n",
        "    if pokemon_data.loc[i][\"#\"]==pokemon_id:\n",
        "      return pokemon_data.loc[i][\"Name\"]\n",
        "\n",
        "def print_simulate_msg(win, opponent, our):\n",
        "  opponent_pokemon_name = search_pokemon_name(opponent)\n",
        "  our_pokemon_name = search_pokemon_name(our)\n",
        "  print(\"opponent: {} ({})\".format(opponent, opponent_pokemon_name))\n",
        "  print(\"our: {} ({})\".format(our, our_pokemon_name))\n",
        "  if (win ==1):\n",
        "    # opponent win\n",
        "    print(\"winner: {}\".format(opponent))\n",
        "  else:\n",
        "    # our win\n",
        "    print(\"winner: {}\".format(our))\n",
        "  print(\"\")\n",
        "\n",
        "def update_remained_pokemon(win, my_pokemon, opp_idx, opponent_pokemon, remained_opponents, remained_ours, data_battle):\n",
        "  \"\"\"\n",
        "  Based on the result of the fight, update the opponent/our remained pokemon list and update the survived pokemon hp feature value.\n",
        "\n",
        "  INPUT\n",
        "  win: the result of the fight\n",
        "  my_pokemon: the pokemon fought in this round\n",
        "\n",
        "  \"\"\"\n",
        "  # 패배한 포켓몬은 remained list에서 제거\n",
        "  if (win == 1):\n",
        "    # opponent win -> our pokemon이 제거되어야 한다\n",
        "    data_battle = node_feature_update(opponents[opp_idx], my_pokemon, data_battle)\n",
        "\n",
        "    remained_ours.remove(my_pokemon)\n",
        "  else:\n",
        "    # we win -> opponent pokemon이 제거되어야 한다.\n",
        "    data_battle = node_feature_update(my_pokemon, opponents[opp_idx], data_battle)\n",
        "\n",
        "    remained_opponents.remove(opponents[opp_idx])\n",
        "    opp_idx += 1 # battle 할 다음 opponent 포켓몬을 indexing 하도록 한다.\n",
        "\n",
        "  return remained_opponents, remained_ours, opp_idx, data_battle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vG6dESZwuvgO"
      },
      "outputs": [],
      "source": [
        "# model input: data, edge_index, neg_edge_index\n",
        "# edge index를 생성하여 predict를 하자.\n",
        "# node 1(head): loser, node 2(tail): winner이라는 것에 대해서 추측하는 것\n",
        "\n",
        "# 6마리의 pokemon을 받는다.\n",
        "# edge_index: [[losers], [winners]]인데 그냥 [[opponent's pokemons], [our pokemons]]로 넣고 edge prediction 진행\n",
        "def simulate(model, opponents, ours, data_battle):\n",
        "  \"\"\"\n",
        "  Simulate the battle between our 6 pokemons and opponent's 6 pokemons\n",
        "\n",
        "  INPUT\n",
        "  model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n",
        "  opponents: list of opponent's 6 pokemon ids\n",
        "  ours: list of our 6 pokemon ids\n",
        "  data_battle: data object for the battle\n",
        "  \"\"\"\n",
        "  random.shuffle(opponents) # opponent\n",
        "  win = 0 # 0: start, 1: opponent win , 2: ours win\n",
        "  opp_idx, our_idx = 0, 0\n",
        "  remained_opponents, remained_ours = copy.deepcopy(opponents), ours\n",
        "  round = 1 # round #\n",
        "\n",
        "  while (len(remained_opponents)!=0 and len(remained_ours)!=0): # ours 또는 opponents 중 하나가 0이 될 때까지 repeat\n",
        "    print(\"Round {}.\".format(round))\n",
        "    if win==2: # 전 라운드에 우리가 이겼다면 my_pokemon이 input으로 들어가야 한다.\n",
        "      win, _ = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon)\n",
        "    else: # 상대 팀이 이겼었다면 my_pokemon 새로 뽑아야 한다.\n",
        "      win, my_pokemon = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle)\n",
        "    print_simulate_msg(win, opponents[opp_idx], my_pokemon)\n",
        "    remained_opponents, remained_ours, opp_idx,data_battle = update_remained_pokemon(win, my_pokemon, opp_idx, opponents[opp_idx], remained_opponents, remained_ours, data_battle)\n",
        "\n",
        "    round += 1\n",
        "\n",
        "  if (len(remained_ours)==0):\n",
        "    print(\"You lose...\")\n",
        "\n",
        "  else:\n",
        "    print(\"You win!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAqESd3XuybM",
        "outputId": "2ae380fa-4a57-4f2c-8cc9-4887b96eca56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 1.\n",
            "opponent: 382 (Milotic)\n",
            "our: 123 (Kangaskhan)\n",
            "winner: 123\n",
            "\n",
            "Round 2.\n",
            "opponent: 155 (Snorlax)\n",
            "our: 123 (Kangaskhan)\n",
            "winner: 155\n",
            "\n",
            "Round 3.\n",
            "opponent: 155 (Snorlax)\n",
            "our: 775 (Sliggoo)\n",
            "winner: 775\n",
            "\n",
            "Round 4.\n",
            "opponent: 610 (Basculin)\n",
            "our: 775 (Sliggoo)\n",
            "winner: 610\n",
            "\n",
            "Round 5.\n",
            "opponent: 610 (Basculin)\n",
            "our: 718 (Chespin)\n",
            "winner: 718\n",
            "\n",
            "Round 6.\n",
            "opponent: 100 (Haunter)\n",
            "our: 718 (Chespin)\n",
            "winner: 100\n",
            "\n",
            "Round 7.\n",
            "opponent: 100 (Haunter)\n",
            "our: 635 (Gothita)\n",
            "winner: 100\n",
            "\n",
            "Round 8.\n",
            "opponent: 100 (Haunter)\n",
            "our: 356 (Spoink)\n",
            "winner: 100\n",
            "\n",
            "Round 9.\n",
            "opponent: 100 (Haunter)\n",
            "our: 357 (Grumpig)\n",
            "winner: 100\n",
            "\n",
            "You lose...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "opponents = [132, 155, 610, 382, 100, 519]\n",
        "ours = [718, 357, 775, 356, 123, 635]\n",
        "\n",
        "\n",
        "model = [gcn_model, graphsage_mean_model, graphsage_max_model, gat_model]\n",
        "data_battle = copy.deepcopy(data_total)\n",
        "simulate(model[3], opponents, ours, data_battle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euNqF3yBLM50"
      },
      "source": [
        "## Short output simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HNkLC6DGCP3F"
      },
      "outputs": [],
      "source": [
        "# # model input: data, edge_index, neg_edge_index\n",
        "# # edge index를 생성하여 predict를 하자.\n",
        "# # node 1(head): loser, node 2(tail): winner이라는 것에 대해서 추측하는 것\n",
        "\n",
        "# # 6마리의 pokemon을 받는다.\n",
        "# # edge_index: [[losers], [winners]]인데 그냥 [[opponent's pokemons], [our pokemons]]로 넣고 edge prediction 진행\n",
        "# def short_simulate(model, opponents, ours, data_battle):\n",
        "#   \"\"\"\n",
        "#   Simulate the battle between our 6 pokemons and opponent's 6 pokemons (short result version)\n",
        "\n",
        "#   INPUT\n",
        "#   model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n",
        "#   opponents: list of opponent's 6 pokemon ids\n",
        "#   ours: list of our 6 pokemon ids\n",
        "#   data_battle: data object for the battle\n",
        "#   \"\"\"\n",
        "#   random.shuffle(opponents) # opponent\n",
        "#   win = 0 # 0: start, 1: opponent win , 2: ours win\n",
        "#   opp_idx, our_idx = 0, 0\n",
        "#   remained_opponents, remained_ours = copy.deepcopy(opponents), ours\n",
        "#   round = 1 # round #\n",
        "#   printing = True\n",
        "\n",
        "#   while (len(remained_opponents)!=0 and len(remained_ours)!=0): # ours 또는 opponents 중 하나가 0이 될 때까지 repeat\n",
        "#     if (len(remained_opponents)==1 or len(remained_ours)==1):\n",
        "#       printing=True\n",
        "#     if printing:\n",
        "#       print(\"Round {}.\".format(round))\n",
        "#     if win==2: # 전 라운드에 우리가 이겼다면 my_pokemon이 input으로 들어가야 한다.\n",
        "#       win, _ = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon)\n",
        "#     else: # 상대 팀이 이겼었다면 my_pokemon 새로 뽑아야 한다.\n",
        "#       win, my_pokemon = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle)\n",
        "\n",
        "#     if printing:\n",
        "#       print_simulate_msg(win, opponents[opp_idx], my_pokemon)\n",
        "#     if round == 2:\n",
        "#       print(\"...\")\n",
        "#       print()\n",
        "#       printing=False\n",
        "\n",
        "#     remained_opponents, remained_ours, opp_idx,data_battle = update_remained_pokemon(win, my_pokemon, opp_idx, opponents[opp_idx], remained_opponents, remained_ours, data_battle)\n",
        "\n",
        "#     round += 1\n",
        "\n",
        "#   if (len(remained_ours)==0):\n",
        "#     print(\"You lose...\")\n",
        "\n",
        "#   else:\n",
        "#     print(\"You win!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UcemBbl0CP3F"
      },
      "outputs": [],
      "source": [
        "# ours = [132, 155, 610, 382, 100, 519]\n",
        "# opponents = [718, 357, 775, 356, 123, 635]\n",
        "\n",
        "\n",
        "# model = [gcn_model, graphsage_mean_model, graphsage_max_model, gat_model]\n",
        "# data_battle = copy.deepcopy(data_total)\n",
        "# short_simulate(model[3], opponents, ours, data_battle)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
