{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RkSe5fXKrY8G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716815953580,"user_tz":-540,"elapsed":183591,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}},"outputId":"d87a37ea-7ab0-4e80-b472-793e254c8289"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown==5.2.0 in /usr/local/lib/python3.10/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0) (3.14.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==5.2.0) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0) (1.7.1)\n","Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (3.7.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (9.4.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2) (1.16.0)\n","Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (1.24.3)\n","Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (1.24.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\n","Collecting scikit-learn==1.3.0\n","  Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0) (1.24.3)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0) (3.5.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed scikit-learn-1.3.0\n","Collecting torch==2.1.2\n","  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.14.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.1.0 (from torch==2.1.2)\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.2 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 triton-2.1.0\n","Collecting torch-geometric==2.5.3\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.24.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.3.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.5.3) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.5.3) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.5.3) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}],"source":["!pip install gdown==5.2.0\n","!pip install matplotlib==3.7.2\n","!pip install numpy==1.24.3\n","!pip install pandas==2.0.3\n","!pip install scikit-learn==1.3.0\n","!pip install torch==2.1.2\n","!pip install torch-geometric==2.5.3"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axJ9tf7vswKn","outputId":"5eb781e4-0b11-444f-bd8b-491d9b076204","executionInfo":{"status":"ok","timestamp":1716815979962,"user_tz":-540,"elapsed":1574,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CS471_Pokemon_battle_prediction'...\n","remote: Enumerating objects: 41, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (34/34), done.\u001b[K\n","remote: Total 41 (delta 14), reused 25 (delta 5), pack-reused 0\u001b[K\n","Receiving objects: 100% (41/41), 308.60 KiB | 1.21 MiB/s, done.\n","Resolving deltas: 100% (14/14), done.\n"]}],"source":["\"\"\"\n","Dataset download from Google Drive using gdown\n","\"\"\"\n","\n","!git clone https://github.com/hyein99/CS471_Pokemon_battle_prediction.git\n"]},{"cell_type":"markdown","metadata":{"id":"JNybONnWrY8G"},"source":["# Import Modules"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"tizSUrJmrY8H","executionInfo":{"status":"ok","timestamp":1716815989090,"user_tz":-540,"elapsed":7013,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import pandas as pd\n","import copy\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5xMrCdFArY8H","executionInfo":{"status":"ok","timestamp":1716815989091,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["SEED = 42\n","deterministic = True\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","if deterministic:\n","\ttorch.backends.cudnn.deterministic = True\n","\ttorch.backends.cudnn"]},{"cell_type":"markdown","metadata":{"id":"oQXcMk2erY8H"},"source":["# Data Pre-processing"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"C_0Xb4tPrY8H","executionInfo":{"status":"ok","timestamp":1716815991504,"user_tz":-540,"elapsed":316,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["# Load pokemon.csv and combats.csv\n","pokemon_data = pd.read_csv('./CS471_Pokemon_battle_prediction/dataset/pokemon.csv')\n","combats_data = pd.read_csv('./CS471_Pokemon_battle_prediction/dataset/combats.csv')\n","\n","# Encode vertex values to unique integers\n","label_encoder = LabelEncoder()\n","pokemon_data['#'] = label_encoder.fit_transform(pokemon_data['#'])\n","combats_data[['First_pokemon', 'Second_pokemon', 'Winner']] = \\\n","    combats_data[['First_pokemon', 'Second_pokemon', 'Winner']].apply(label_encoder.transform)\n","\n","features_to_normalize = ['HP', 'Attack', 'Defense', 'Speed', 'Generation', 'Sp. Atk', 'Sp. Def']\n","features_else = ['Type 1_Bug', 'Type 1_Dark', 'Type 1_Dragon', 'Type 1_Electric',\n","              'Type 1_Fairy', 'Type 1_Fighting', 'Type 1_Fire', 'Type 1_Flying',\n","              'Type 1_Ghost', 'Type 1_Grass', 'Type 1_Ground', 'Type 1_Ice',\n","              'Type 1_Normal', 'Type 1_Poison', 'Type 1_Psychic', 'Type 1_Rock',\n","              'Type 1_Steel', 'Type 1_Water', 'Type 2_Bug', 'Type 2_Dark',\n","              'Type 2_Dragon', 'Type 2_Electric', 'Type 2_Fairy', 'Type 2_Fighting',\n","              'Type 2_Fire', 'Type 2_Flying', 'Type 2_Ghost', 'Type 2_Grass',\n","              'Type 2_Ground', 'Type 2_Ice', 'Type 2_Normal', 'Type 2_Poison',\n","              'Type 2_Psychic', 'Type 2_Rock', 'Type 2_Steel', 'Type 2_Water']\n","\n","scaler = MinMaxScaler()\n","\n","pokemon_data[features_to_normalize] = \\\n","    scaler.fit_transform(pokemon_data[features_to_normalize])\n","\n","\n","pokemon_data = pd.get_dummies(pokemon_data, columns=['Type 1', 'Type 2'])\n","pokemon_data[features_else] = \\\n","    pokemon_data[features_else].astype(int)\n","\n","hp_weight = 5.0\n","pokemon_data['HP'] *= hp_weight\n","\n","pokemon_data['Legendary'] = pokemon_data['Legendary'].astype(int)\n","pokemon_data['total_stat'] = pokemon_data[features_to_normalize].sum(axis=1)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wbpDGPs0rY8H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716815993143,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}},"outputId":"bf3a0b21-1d60-4d2a-edce-f347ed13ad0f"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-48927d68a4a0>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_pokemon['#'] = label_encoder.inverse_transform(train_pokemon['#'])\n","<ipython-input-6-48927d68a4a0>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_pokemon['#'] = label_encoder.inverse_transform(test_pokemon['#'])\n"]}],"source":["# Split combats data into train and test\n","train_combats, test_combats = train_test_split(combats_data, test_size=0.2, random_state=SEED)\n","\n","# Extract unique vertex values from train_combats and test_combats\n","train_vertices = set(train_combats['First_pokemon']).union(set(train_combats['Second_pokemon']))\n","test_vertices = set(test_combats['First_pokemon']).union(set(test_combats['Second_pokemon']))\n","\n","# Split pokemon data into train and test based on the vertices\n","train_pokemon = pokemon_data[pokemon_data['#'].isin(train_vertices)]\n","test_pokemon = pokemon_data[pokemon_data['#'].isin(test_vertices)]\n","\n","# Decode vertex values back to original values if needed\n","train_pokemon['#'] = label_encoder.inverse_transform(train_pokemon['#'])\n","test_pokemon['#'] = label_encoder.inverse_transform(test_pokemon['#'])\n","\n","# Set \"#\" as index for train_pokemon and test_pokemon dataframes\n","train_pokemon.set_index('#', inplace=True)\n","test_pokemon.set_index('#', inplace=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gjzSj-q6rY8H","executionInfo":{"status":"ok","timestamp":1716815995514,"user_tz":-540,"elapsed":2372,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["features = ['total_stat']+features_to_normalize + features_else\n","\n","X_data = pokemon_data[features].values\n","X_data = torch.tensor(X_data, dtype=torch.float)\n","\n","# for train dataset\n","X_train = train_pokemon[features].values\n","X_train = torch.tensor(X_train, dtype=torch.float)\n","edges_train = []\n","neg_edge_index_train = []\n","\n","for _, row in train_combats.iterrows():\n","    first_pokemon = row['First_pokemon']\n","    second_pokemon = row['Second_pokemon']\n","    winner = row['Winner']\n","\n","    if first_pokemon == winner:\n","      edges_train.append((second_pokemon, first_pokemon))\n","      neg_edge_index_train.append((first_pokemon, second_pokemon))\n","\n","    else:\n","      edges_train.append((first_pokemon, second_pokemon))\n","      neg_edge_index_train.append((second_pokemon, first_pokemon))\n","\n","neg_edge_index_train = torch.tensor(neg_edge_index_train, dtype=torch.long).t()\n","edge_index_train = torch.tensor(edges_train, dtype=torch.long).t()\n","\n","data_train = Data(x=X_data, edge_index=edge_index_train, neg_edge_index = neg_edge_index_train)\n","train_loader = DataLoader([data_train], batch_size=1, shuffle=True)\n","\n","# for test dataset\n","X_test = test_pokemon[features].values\n","X_test = torch.tensor(X_test, dtype=torch.float)\n","edges_test = []\n","neg_edge_index_test = []\n","\n","for _, row in test_combats.iterrows():\n","    first_pokemon = row['First_pokemon']\n","    second_pokemon = row['Second_pokemon']\n","    winner = row['Winner']\n","\n","    if first_pokemon == winner:\n","      edges_test.append((second_pokemon, first_pokemon))\n","      neg_edge_index_test.append((first_pokemon, second_pokemon))\n","\n","    else:\n","      edges_test.append((first_pokemon, second_pokemon))\n","      neg_edge_index_test.append((second_pokemon, first_pokemon))\n","\n","edge_index_test = torch.tensor(edges_test, dtype=torch.long).t()\n","neg_edge_index_test = torch.tensor(neg_edge_index_test, dtype=torch.long).t()\n","\n","data_test = Data(x=X_data, edge_index=edge_index_test, neg_edge_index= neg_edge_index_test)\n","test_loader = DataLoader([data_test], batch_size=1, shuffle=False)\n","\n","# for total data\n","edge = edges_train\n","edge.extend(edges_test)\n","edge_index = torch.tensor(edge, dtype=torch.long).t()\n","\n","data_total = Data(x=X_data, edge_index = edge_index)"]},{"cell_type":"markdown","metadata":{"id":"m4a2j3ZVCP3D"},"source":["# Model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"bXIEAye8CP3D","executionInfo":{"status":"ok","timestamp":1716815995515,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# GCN and GraphSage\n","class GraphSageLayer(nn.Module):\n","    def __init__(self, dim_in: int, dim_out: int, agg_type: str):\n","        super(GraphSageLayer, self).__init__()\n","        self.dim_in = dim_in\n","        self.dim_out = dim_out\n","        self.agg_type = agg_type\n","        self.act = nn.ReLU()\n","\n","        if self.agg_type == 'gcn':\n","            self.weight = nn.Linear(self.dim_in, self.dim_out, bias=False)\n","            self.bias = nn.Linear(self.dim_in, self.dim_out, bias=False)\n","\n","        elif self.agg_type == 'mean':\n","            self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False)\n","\n","        elif self.agg_type == 'maxpool':\n","            self.linear_pool = nn.Linear(self.dim_in, self.dim_in, bias=True)\n","            self.weight = nn.Linear(2 * self.dim_in, self.dim_out, bias=False)\n","\n","        else:\n","            raise RuntimeError(f\"Unknown aggregation type: {self.agg_type}\")\n","\n","    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n","        if self.agg_type == 'gcn':\n","            feat_h = feat[edge[0]]\n","            idx_t = edge[1]\n","            agg_neighbor = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n","            agg_neighbor = agg_neighbor.index_add_(0, idx_t, feat_h)\n","            degree = torch.bincount(idx_t, minlength=feat.size(0)).unsqueeze(1).to(feat.device)\n","            inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree)\n","            feat_agg = agg_neighbor * inv_degree\n","            out = F.normalize(self.act(self.weight(feat_agg) + self.bias(feat)), 2, -1)\n","\n","        elif self.agg_type == 'mean':\n","            feat_h = feat[edge[0]]\n","            idx_t = edge[1]\n","            agg_neighbor = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n","            agg_neighbor = agg_neighbor.index_add_(0, idx_t, feat_h)\n","            degree = torch.bincount(idx_t, minlength=feat.size(0)).unsqueeze(1).to(feat.device)\n","            inv_degree = torch.where(degree == 0.0, 1.0, 1.0 / degree)\n","            feat_agg = agg_neighbor * inv_degree\n","            out = F.normalize(self.act(self.weight(torch.cat((feat_agg, feat), 1))), 2, -1)\n","\n","        elif self.agg_type == 'maxpool':\n","            feat = self.act(self.linear_pool(feat))\n","            feat_h = feat[edge[0]]\n","            idx_t = edge[1]\n","            scatter_idx = idx_t.unsqueeze(-1).repeat(1, feat.size(1))\n","            feat_agg = torch.zeros(feat.size(0), feat.size(1), dtype=torch.float32).to(feat.device)\n","            feat_agg = feat_agg.scatter_reduce(0, scatter_idx, feat_h, reduce='amax', include_self=False)\n","            out = F.normalize(self.act(self.weight(torch.cat((feat_agg, feat), 1))), 2, -1)\n","\n","        else:\n","            raise RuntimeError(f\"Unknown aggregation type: {self.agg_type}\")\n","\n","        return out\n","\n","class GraphSage(nn.Module):\n","    def __init__(self, num_layers: int, dim_in: int, dim_hidden: int, dim_out: int, agg_type: str):\n","        super(GraphSage, self).__init__()\n","        self.num_layers = num_layers\n","        self.dim_in = dim_in\n","        self.dim_hidden = dim_hidden\n","        self.dim_out = dim_out\n","        self.agg_type = agg_type\n","\n","        self.layers = nn.ModuleList()\n","        for l in range(num_layers):\n","            self.layers.append(GraphSageLayer(self.dim_in if l == 0 else self.dim_hidden, self.dim_hidden, agg_type))\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2 * self.dim_hidden, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n","        x_in = feat\n","        for layer in self.layers:\n","            x_out = layer(x_in, edge)\n","            x_in = x_out\n","        return x_out\n","\n","    def predict(self, head: torch.Tensor, tail: torch.Tensor) -> torch.Tensor:\n","        head_tail = torch.cat([head, tail], dim=-1)\n","        score = self.classifier(head_tail)\n","        return score\n","\n","# GAT\n","# GAT\n","class GATLayer(nn.Module):\n","    def __init__(self, in_dim: int, out_dim: int, dropout: float = 0.5, alpha: float = 0.2) -> None:\n","        super(GATLayer, self).__init__()\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.dropout = dropout\n","        self.alpha = alpha\n","\n","        self.W = nn.Parameter(torch.empty(size=(in_dim, out_dim)))\n","        nn.init.xavier_uniform_(self.W.data)\n","        self.a = nn.Parameter(torch.empty(size=(2 * out_dim, 1)))\n","        nn.init.xavier_uniform_(self.a.data)\n","\n","        self.leakyrelu = nn.LeakyReLU(negative_slope=self.alpha)\n","        self.batch_norm = nn.BatchNorm1d(out_dim)\n","        self.dropout_layer = nn.Dropout(p=self.dropout)\n","        self.residual = nn.Linear(in_dim, out_dim)\n","\n","    def forward(self, feat: torch.Tensor, edges: torch.Tensor) -> torch.Tensor:\n","        message = feat @ self.W\n","        attn_src = message @ self.a[:self.out_dim, :]\n","        attn_dst = message @ self.a[self.out_dim:, :]\n","\n","        src, dst = edges\n","        attn_scores = self.leakyrelu(attn_src[src] + attn_dst[dst])\n","        attn_scores = attn_scores - attn_scores.max()  # for stabilization of softmax\n","\n","        # Edge softmax\n","        exp_attn_scores = attn_scores.exp()\n","        exp_sum = torch.zeros((feat.shape[0], 1), device=feat.device).scatter_add_(\n","            dim=0,\n","            index=dst.unsqueeze(1),\n","            src=exp_attn_scores\n","        ) + 1e-10  # Prevent division by zero\n","\n","        attn_coeffs = exp_attn_scores / exp_sum[dst]\n","        attn_coeffs = self.dropout_layer(attn_coeffs)\n","\n","        # Weighted aggregation\n","        out = torch.zeros_like(message, device=feat.device).scatter_add_(\n","            dim=0,\n","            index=dst.unsqueeze(1).expand(-1, self.out_dim),\n","            src=message[src] * attn_coeffs\n","        )\n","        out += self.residual(feat)  # Residual connection\n","        out = self.batch_norm(out)\n","        return out\n","\n","#GAT\n","class GAT(nn.Module):\n","    def __init__(self, dim_in: int, dim_hidden: int, dim_out: int, dropout: float = 0.5, alpha: float = 0.2, num_heads: int = 8) -> None:\n","        super(GAT, self).__init__()\n","        self.dim_in = dim_in\n","        self.dim_hidden = dim_hidden\n","        self.dim_out = dim_out\n","        self.dropout = dropout\n","        self.num_heads = num_heads\n","\n","        self.attn_heads1 = nn.ModuleList()\n","        for _ in range(num_heads):\n","            self.attn_heads1.append(\n","                GATLayer(self.dim_in, self.dim_hidden, dropout=dropout, alpha=alpha)\n","            )\n","\n","        self.attn_heads2 = nn.ModuleList()\n","        for _ in range(num_heads):\n","            self.attn_heads2.append(\n","                GATLayer(self.dim_hidden * num_heads, self.dim_hidden, dropout=dropout, alpha=alpha)\n","            )\n","\n","        self.output_layer = GATLayer(self.dim_hidden * num_heads, self.dim_out, dropout=dropout, alpha=alpha)\n","        self.residual = nn.Linear(self.dim_in, self.dim_out)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2 * self.dim_out, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, feat: torch.Tensor, edge: torch.Tensor) -> torch.Tensor:\n","        x_in = feat\n","\n","        multi_head_out1 = []\n","        for attn_head in self.attn_heads1:\n","            multi_head_out1.append(attn_head(x_in, edge))\n","        x_out1 = torch.cat(multi_head_out1, dim=-1)\n","\n","        multi_head_out2 = []\n","        for attn_head in self.attn_heads2:\n","            multi_head_out2.append(attn_head(x_out1, edge))\n","        x_out2 = torch.cat(multi_head_out2, dim=-1)\n","\n","        x_out = self.output_layer(x_out2, edge)\n","        x_out += self.residual(x_in)  # Residual connection\n","        return x_out\n","\n","    def predict(self, head: torch.Tensor, tail: torch.Tensor) -> torch.Tensor:\n","        head_tail = torch.cat([head, tail], dim=-1)\n","        score = self.classifier(head_tail)\n","        return score"]},{"cell_type":"markdown","metadata":{"id":"9PIWFHRYrY8I"},"source":["# Define Train, Test, Predict Frameworks"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MlzM70M3rY8I","executionInfo":{"status":"ok","timestamp":1716815995515,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["def train(model, optimizer, train_loader, device):\n","    model.train()\n","    total_loss = 0\n","\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        out = model(data.x, data.edge_index)\n","\n","        pos_edge_index = data.edge_index\n","        neg_edge_index = data.neg_edge_index\n","\n","        pos_head = out[pos_edge_index[0]]\n","        pos_tail = out[pos_edge_index[1]]\n","        neg_head = out[neg_edge_index[0]]\n","        neg_tail = out[neg_edge_index[1]]\n","\n","        pos_pred = model.predict(pos_head, pos_tail)\n","        neg_pred = model.predict(neg_head, neg_tail)\n","\n","        pos_loss = F.binary_cross_entropy_with_logits(pos_pred, torch.ones_like(pos_pred))\n","        neg_loss = F.binary_cross_entropy_with_logits(neg_pred, torch.zeros_like(neg_pred))\n","        loss = pos_loss + neg_loss\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    return total_loss / len(train_loader)\n","\n","def test(model, loader, device):\n","    model.eval()\n","    auc = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            data = data.to(device)\n","            out = model(data.x, data.edge_index)\n","\n","            pos_edge_index = data.edge_index\n","            neg_edge_index = data.neg_edge_index\n","\n","            pos_head = out[pos_edge_index[0]]\n","            pos_tail = out[pos_edge_index[1]]\n","            neg_head = out[neg_edge_index[0]]\n","            neg_tail = out[neg_edge_index[1]]\n","\n","            pos_pred = model.predict(pos_head, pos_tail)\n","            neg_pred = model.predict(neg_head, neg_tail)\n","            preds = torch.cat([pos_pred, neg_pred])\n","\n","            pos_labels = torch.ones_like(pos_pred)\n","            neg_labels = torch.zeros_like(neg_pred)\n","            labels = torch.cat([pos_labels, neg_labels])\n","\n","            auc += roc_auc_score(labels.cpu(), preds.cpu())\n","\n","    return auc / len(loader)\n","\n","def predict(model, head, tail, data, device):\n","    model.eval()\n","    with torch.no_grad():\n","        data = data.to(device)\n","        out = model(data.x, data.edge_index)\n","        head_feature = out[head]\n","        tail_feature = out[tail]\n","        score = model.predict(head_feature, tail_feature)\n","        reverse_score = model.predict(tail_feature, head_feature)\n","        return torch.sigmoid(score).item(), torch.sigmoid(reverse_score).item()"]},{"cell_type":"markdown","metadata":{"id":"kVG6f97PrY8I"},"source":["# Train"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sp0NfQAgrY8I","executionInfo":{"status":"ok","timestamp":1716815996677,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["# Choose model from [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]\n","def train_model(epoch, model_type, data_train, data_test, train_loader, test_loader, device):\n","    EPOCH = epoch\n","    MODEL = model_type\n","\n","    if MODEL == \"GCN\":\n","        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"gcn\")\n","    elif MODEL == \"GraphSage_mean\":\n","        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"mean\")\n","    elif MODEL == \"GraphSage_maxpool\":\n","        model = GraphSage(num_layers=2, dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, agg_type=\"maxpool\")\n","    elif MODEL == \"GAT\":\n","        model = GAT(dim_in=X_data.shape[1], dim_hidden=64, dim_out=8, dropout = 0.5, alpha = 0.2, num_heads = 8)\n","\n","    model = model.to(device)\n","\n","    data_train = data_train.to(device)\n","    data_test = data_test.to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=5e-4)\n","\n","    patience = 3 # for early stopping\n","    best_loss = float('inf')\n","    epochs_no_improve = 0\n","\n","    for epoch in range(EPOCH):\n","        loss = train(model, optimizer, train_loader, device)\n","        if epoch % 10 == 0:\n","            test_auc = test(model, test_loader, device)\n","            train_auc = test(model, train_loader, device)\n","            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Test AUC: {test_auc:.4f}')\n","            if loss < best_loss:\n","                best_loss = loss\n","                epochs_no_improve = 0\n","            else:\n","                epochs_no_improve += 1\n","                if epochs_no_improve == patience:\n","                    print(\"Early stopping triggered\")\n","                    break\n","    return model\n","\n","# calculate prediction accuracy\n","def test_model(model, data_total, data_test, device):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    head_list, tail_list = data_test.edge_index\n","    head_list = list(head_list)\n","    tail_list = list(tail_list)\n","\n","    pos = 0\n","    for idx in range(len(head_list)):\n","        head = head_list[idx]\n","        tail = tail_list[idx]\n","        prediction, reverse_prediction = predict(model, head, tail, data_total, device)\n","        if prediction > reverse_prediction:\n","            pos += 1\n","\n","    print(f\"Prediction accuracy: {pos/len(head_list)}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"y9-kgvvsrY8I","executionInfo":{"status":"ok","timestamp":1716815997313,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# select model from model_types\n","model_types = [\"GCN\", \"GraphSage_mean\", \"GraphSage_maxpool\", \"GAT\"]\n","epoch = 600"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwIlFFS0rY8I","outputId":"233db9ea-c7e4-4b1b-93b8-9f1f9e3478dd","executionInfo":{"status":"ok","timestamp":1716816030549,"user_tz":-540,"elapsed":32789,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000, Loss: 1.3873, Train AUC: 0.6845, Test AUC: 0.6416\n","Epoch: 010, Loss: 1.0512, Train AUC: 0.8673, Test AUC: 0.8499\n","Epoch: 020, Loss: 0.7299, Train AUC: 0.9224, Test AUC: 0.8947\n","Epoch: 030, Loss: 0.6726, Train AUC: 0.9324, Test AUC: 0.9151\n","Epoch: 040, Loss: 0.6301, Train AUC: 0.9396, Test AUC: 0.9265\n","Epoch: 050, Loss: 0.5747, Train AUC: 0.9525, Test AUC: 0.9396\n","Epoch: 060, Loss: 0.5589, Train AUC: 0.9616, Test AUC: 0.9470\n","Epoch: 070, Loss: 0.4913, Train AUC: 0.9649, Test AUC: 0.9502\n","Epoch: 080, Loss: 0.4574, Train AUC: 0.9694, Test AUC: 0.9543\n","Epoch: 090, Loss: 0.4691, Train AUC: 0.9711, Test AUC: 0.9531\n","Epoch: 100, Loss: 0.4094, Train AUC: 0.9746, Test AUC: 0.9579\n","Epoch: 110, Loss: 0.3893, Train AUC: 0.9780, Test AUC: 0.9564\n","Epoch: 120, Loss: 0.3752, Train AUC: 0.9795, Test AUC: 0.9548\n","Epoch: 130, Loss: 0.3621, Train AUC: 0.9809, Test AUC: 0.9555\n","Epoch: 140, Loss: 0.3495, Train AUC: 0.9816, Test AUC: 0.9583\n","Epoch: 150, Loss: 0.3554, Train AUC: 0.9821, Test AUC: 0.9555\n","Epoch: 160, Loss: 0.3339, Train AUC: 0.9834, Test AUC: 0.9550\n","Epoch: 170, Loss: 0.3252, Train AUC: 0.9832, Test AUC: 0.9585\n","Epoch: 180, Loss: 0.3244, Train AUC: 0.9845, Test AUC: 0.9566\n","Epoch: 190, Loss: 0.3151, Train AUC: 0.9853, Test AUC: 0.9548\n","Epoch: 200, Loss: 0.3121, Train AUC: 0.9856, Test AUC: 0.9561\n","Epoch: 210, Loss: 0.3003, Train AUC: 0.9860, Test AUC: 0.9592\n","Epoch: 220, Loss: 0.3048, Train AUC: 0.9863, Test AUC: 0.9548\n","Epoch: 230, Loss: 0.2964, Train AUC: 0.9868, Test AUC: 0.9585\n","Epoch: 240, Loss: 0.2884, Train AUC: 0.9874, Test AUC: 0.9585\n","Epoch: 250, Loss: 0.2815, Train AUC: 0.9881, Test AUC: 0.9559\n","Epoch: 260, Loss: 0.2804, Train AUC: 0.9884, Test AUC: 0.9556\n","Epoch: 270, Loss: 0.2807, Train AUC: 0.9871, Test AUC: 0.9612\n","Epoch: 280, Loss: 0.2760, Train AUC: 0.9887, Test AUC: 0.9586\n","Epoch: 290, Loss: 0.2670, Train AUC: 0.9894, Test AUC: 0.9539\n","Epoch: 300, Loss: 0.2611, Train AUC: 0.9897, Test AUC: 0.9569\n","Epoch: 310, Loss: 0.2586, Train AUC: 0.9901, Test AUC: 0.9578\n","Epoch: 320, Loss: 0.3497, Train AUC: 0.9844, Test AUC: 0.9603\n","Epoch: 330, Loss: 0.2821, Train AUC: 0.9886, Test AUC: 0.9598\n","Epoch: 340, Loss: 0.2591, Train AUC: 0.9899, Test AUC: 0.9582\n","Early stopping triggered\n","Prediction accuracy: 0.9306\n"]}],"source":["gcn_model = train_model(epoch, \"GCN\", data_train, data_test, train_loader, test_loader, device)\n","test_model(gcn_model, data_total, data_test, device)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaBx2nb6rY8I","outputId":"12de768b-d918-48a9-8594-c21d2bb61ff9","executionInfo":{"status":"ok","timestamp":1716816059538,"user_tz":-540,"elapsed":28999,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000, Loss: 1.3866, Train AUC: 0.6542, Test AUC: 0.6416\n","Epoch: 010, Loss: 0.9678, Train AUC: 0.8702, Test AUC: 0.8476\n","Epoch: 020, Loss: 0.7283, Train AUC: 0.9228, Test AUC: 0.8979\n","Epoch: 030, Loss: 0.6678, Train AUC: 0.9322, Test AUC: 0.9151\n","Epoch: 040, Loss: 0.6233, Train AUC: 0.9410, Test AUC: 0.9292\n","Epoch: 050, Loss: 0.5661, Train AUC: 0.9474, Test AUC: 0.9387\n","Epoch: 060, Loss: 0.5470, Train AUC: 0.9590, Test AUC: 0.9477\n","Epoch: 070, Loss: 0.4963, Train AUC: 0.9646, Test AUC: 0.9534\n","Epoch: 080, Loss: 0.4602, Train AUC: 0.9694, Test AUC: 0.9571\n","Epoch: 090, Loss: 0.4396, Train AUC: 0.9732, Test AUC: 0.9591\n","Epoch: 100, Loss: 0.4024, Train AUC: 0.9759, Test AUC: 0.9623\n","Epoch: 110, Loss: 0.3923, Train AUC: 0.9781, Test AUC: 0.9616\n","Epoch: 120, Loss: 0.3733, Train AUC: 0.9797, Test AUC: 0.9611\n","Epoch: 130, Loss: 0.3573, Train AUC: 0.9809, Test AUC: 0.9621\n","Epoch: 140, Loss: 0.3503, Train AUC: 0.9819, Test AUC: 0.9635\n","Epoch: 150, Loss: 0.3505, Train AUC: 0.9824, Test AUC: 0.9618\n","Epoch: 160, Loss: 0.3371, Train AUC: 0.9834, Test AUC: 0.9617\n","Epoch: 170, Loss: 0.3277, Train AUC: 0.9838, Test AUC: 0.9628\n","Epoch: 180, Loss: 0.3182, Train AUC: 0.9845, Test AUC: 0.9616\n","Epoch: 190, Loss: 0.3621, Train AUC: 0.9809, Test AUC: 0.9653\n","Epoch: 200, Loss: 0.3248, Train AUC: 0.9832, Test AUC: 0.9622\n","Epoch: 210, Loss: 0.3138, Train AUC: 0.9850, Test AUC: 0.9625\n","Epoch: 220, Loss: 0.3046, Train AUC: 0.9859, Test AUC: 0.9620\n","Epoch: 230, Loss: 0.2978, Train AUC: 0.9865, Test AUC: 0.9625\n","Epoch: 240, Loss: 0.3011, Train AUC: 0.9866, Test AUC: 0.9588\n","Epoch: 250, Loss: 0.2961, Train AUC: 0.9872, Test AUC: 0.9591\n","Epoch: 260, Loss: 0.2843, Train AUC: 0.9874, Test AUC: 0.9643\n","Epoch: 270, Loss: 0.2820, Train AUC: 0.9878, Test AUC: 0.9625\n","Epoch: 280, Loss: 0.2828, Train AUC: 0.9884, Test AUC: 0.9606\n","Epoch: 290, Loss: 0.2788, Train AUC: 0.9877, Test AUC: 0.9645\n","Epoch: 300, Loss: 0.2757, Train AUC: 0.9883, Test AUC: 0.9634\n","Epoch: 310, Loss: 0.2677, Train AUC: 0.9893, Test AUC: 0.9620\n","Epoch: 320, Loss: 0.2657, Train AUC: 0.9895, Test AUC: 0.9616\n","Epoch: 330, Loss: 0.2632, Train AUC: 0.9896, Test AUC: 0.9621\n","Epoch: 340, Loss: 0.2662, Train AUC: 0.9894, Test AUC: 0.9597\n","Epoch: 350, Loss: 0.2598, Train AUC: 0.9895, Test AUC: 0.9625\n","Epoch: 360, Loss: 0.2504, Train AUC: 0.9907, Test AUC: 0.9608\n","Epoch: 370, Loss: 0.2449, Train AUC: 0.9911, Test AUC: 0.9603\n","Epoch: 380, Loss: 0.2520, Train AUC: 0.9890, Test AUC: 0.9560\n","Epoch: 390, Loss: 0.2438, Train AUC: 0.9906, Test AUC: 0.9638\n","Epoch: 400, Loss: 0.2395, Train AUC: 0.9912, Test AUC: 0.9633\n","Epoch: 410, Loss: 0.2350, Train AUC: 0.9919, Test AUC: 0.9605\n","Epoch: 420, Loss: 0.2382, Train AUC: 0.9911, Test AUC: 0.9583\n","Epoch: 430, Loss: 0.2269, Train AUC: 0.9925, Test AUC: 0.9609\n","Epoch: 440, Loss: 0.2229, Train AUC: 0.9926, Test AUC: 0.9605\n","Epoch: 450, Loss: 0.2555, Train AUC: 0.9893, Test AUC: 0.9647\n","Epoch: 460, Loss: 0.2319, Train AUC: 0.9920, Test AUC: 0.9574\n","Epoch: 470, Loss: 0.2210, Train AUC: 0.9928, Test AUC: 0.9609\n","Epoch: 480, Loss: 0.2129, Train AUC: 0.9933, Test AUC: 0.9595\n","Epoch: 490, Loss: 0.2136, Train AUC: 0.9929, Test AUC: 0.9599\n","Epoch: 500, Loss: 0.2087, Train AUC: 0.9936, Test AUC: 0.9596\n","Epoch: 510, Loss: 0.2023, Train AUC: 0.9938, Test AUC: 0.9610\n","Epoch: 520, Loss: 0.1995, Train AUC: 0.9941, Test AUC: 0.9591\n","Epoch: 530, Loss: 0.2464, Train AUC: 0.9925, Test AUC: 0.9566\n","Epoch: 540, Loss: 0.2068, Train AUC: 0.9939, Test AUC: 0.9603\n","Epoch: 550, Loss: 0.1891, Train AUC: 0.9948, Test AUC: 0.9602\n","Epoch: 560, Loss: 0.1872, Train AUC: 0.9948, Test AUC: 0.9595\n","Epoch: 570, Loss: 0.1814, Train AUC: 0.9952, Test AUC: 0.9606\n","Epoch: 580, Loss: 0.1748, Train AUC: 0.9954, Test AUC: 0.9593\n","Epoch: 590, Loss: 0.1935, Train AUC: 0.9946, Test AUC: 0.9570\n","Prediction accuracy: 0.9363\n"]}],"source":["graphsage_mean_model = train_model(epoch, \"GraphSage_mean\", data_train, data_test, train_loader, test_loader, device)\n","test_model(graphsage_mean_model, data_total, data_test, device)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_0EABqCrY8I","outputId":"f65f7795-01f7-4121-89c6-e6fca0bd5c22","executionInfo":{"status":"ok","timestamp":1716816084077,"user_tz":-540,"elapsed":24552,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000, Loss: 1.3872, Train AUC: 0.7294, Test AUC: 0.7116\n","Epoch: 010, Loss: 1.2419, Train AUC: 0.8562, Test AUC: 0.8461\n","Epoch: 020, Loss: 0.8012, Train AUC: 0.9103, Test AUC: 0.9023\n","Epoch: 030, Loss: 0.7140, Train AUC: 0.9263, Test AUC: 0.9150\n","Epoch: 040, Loss: 0.6773, Train AUC: 0.9328, Test AUC: 0.9246\n","Epoch: 050, Loss: 0.6501, Train AUC: 0.9365, Test AUC: 0.9273\n","Epoch: 060, Loss: 0.6074, Train AUC: 0.9455, Test AUC: 0.9332\n","Epoch: 070, Loss: 0.6041, Train AUC: 0.9440, Test AUC: 0.9337\n","Epoch: 080, Loss: 0.5555, Train AUC: 0.9553, Test AUC: 0.9416\n","Epoch: 090, Loss: 0.5077, Train AUC: 0.9626, Test AUC: 0.9473\n","Epoch: 100, Loss: 0.4819, Train AUC: 0.9680, Test AUC: 0.9526\n","Epoch: 110, Loss: 0.4734, Train AUC: 0.9662, Test AUC: 0.9506\n","Epoch: 120, Loss: 0.4364, Train AUC: 0.9718, Test AUC: 0.9563\n","Epoch: 130, Loss: 0.4052, Train AUC: 0.9752, Test AUC: 0.9581\n","Epoch: 140, Loss: 0.4070, Train AUC: 0.9768, Test AUC: 0.9603\n","Epoch: 150, Loss: 0.3772, Train AUC: 0.9789, Test AUC: 0.9616\n","Epoch: 160, Loss: 0.3615, Train AUC: 0.9802, Test AUC: 0.9633\n","Epoch: 170, Loss: 0.3502, Train AUC: 0.9812, Test AUC: 0.9619\n","Epoch: 180, Loss: 0.3591, Train AUC: 0.9811, Test AUC: 0.9616\n","Epoch: 190, Loss: 0.3396, Train AUC: 0.9827, Test AUC: 0.9632\n","Epoch: 200, Loss: 0.3299, Train AUC: 0.9835, Test AUC: 0.9658\n","Epoch: 210, Loss: 0.3275, Train AUC: 0.9825, Test AUC: 0.9625\n","Epoch: 220, Loss: 0.3935, Train AUC: 0.9832, Test AUC: 0.9673\n","Epoch: 230, Loss: 0.3361, Train AUC: 0.9832, Test AUC: 0.9682\n","Epoch: 240, Loss: 0.3198, Train AUC: 0.9845, Test AUC: 0.9671\n","Epoch: 250, Loss: 0.3116, Train AUC: 0.9853, Test AUC: 0.9667\n","Epoch: 260, Loss: 0.3066, Train AUC: 0.9859, Test AUC: 0.9685\n","Epoch: 270, Loss: 0.3034, Train AUC: 0.9853, Test AUC: 0.9651\n","Epoch: 280, Loss: 0.3084, Train AUC: 0.9861, Test AUC: 0.9688\n","Epoch: 290, Loss: 0.3222, Train AUC: 0.9859, Test AUC: 0.9700\n","Epoch: 300, Loss: 0.2996, Train AUC: 0.9867, Test AUC: 0.9695\n","Epoch: 310, Loss: 0.2923, Train AUC: 0.9872, Test AUC: 0.9688\n","Epoch: 320, Loss: 0.2890, Train AUC: 0.9875, Test AUC: 0.9688\n","Epoch: 330, Loss: 0.2947, Train AUC: 0.9862, Test AUC: 0.9689\n","Epoch: 340, Loss: 0.2841, Train AUC: 0.9873, Test AUC: 0.9680\n","Epoch: 350, Loss: 0.2867, Train AUC: 0.9880, Test AUC: 0.9702\n","Epoch: 360, Loss: 0.2817, Train AUC: 0.9881, Test AUC: 0.9695\n","Epoch: 370, Loss: 0.2777, Train AUC: 0.9884, Test AUC: 0.9694\n","Epoch: 380, Loss: 0.2756, Train AUC: 0.9882, Test AUC: 0.9675\n","Epoch: 390, Loss: 0.3007, Train AUC: 0.9886, Test AUC: 0.9697\n","Epoch: 400, Loss: 0.2846, Train AUC: 0.9876, Test AUC: 0.9685\n","Epoch: 410, Loss: 0.2785, Train AUC: 0.9883, Test AUC: 0.9692\n","Early stopping triggered\n","Prediction accuracy: 0.9274\n"]}],"source":["graphsage_max_model = train_model(epoch, \"GraphSage_maxpool\", data_train, data_test, train_loader, test_loader, device)\n","test_model(graphsage_max_model, data_total, data_test, device)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lY4baGg0rY8I","outputId":"bef8e238-9822-4f62-fe74-9edc52473361","executionInfo":{"status":"ok","timestamp":1716816224151,"user_tz":-540,"elapsed":140091,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000, Loss: 1.4095, Train AUC: 0.6933, Test AUC: 0.6151\n","Epoch: 010, Loss: 0.8029, Train AUC: 0.9078, Test AUC: 0.8989\n","Epoch: 020, Loss: 0.7135, Train AUC: 0.9249, Test AUC: 0.9158\n","Epoch: 030, Loss: 0.6717, Train AUC: 0.9312, Test AUC: 0.9262\n","Epoch: 040, Loss: 0.6228, Train AUC: 0.9384, Test AUC: 0.9352\n","Epoch: 050, Loss: 0.5007, Train AUC: 0.9542, Test AUC: 0.9496\n","Epoch: 060, Loss: 0.4246, Train AUC: 0.9709, Test AUC: 0.9653\n","Epoch: 070, Loss: 0.3886, Train AUC: 0.9765, Test AUC: 0.9721\n","Epoch: 080, Loss: 0.3721, Train AUC: 0.9782, Test AUC: 0.9757\n","Epoch: 090, Loss: 0.3610, Train AUC: 0.9795, Test AUC: 0.9777\n","Epoch: 100, Loss: 0.3533, Train AUC: 0.9805, Test AUC: 0.9785\n","Epoch: 110, Loss: 0.3580, Train AUC: 0.9809, Test AUC: 0.9786\n","Epoch: 120, Loss: 0.3616, Train AUC: 0.9815, Test AUC: 0.9787\n","Epoch: 130, Loss: 0.3466, Train AUC: 0.9813, Test AUC: 0.9786\n","Epoch: 140, Loss: 0.3378, Train AUC: 0.9823, Test AUC: 0.9783\n","Epoch: 150, Loss: 0.3359, Train AUC: 0.9828, Test AUC: 0.9795\n","Epoch: 160, Loss: 0.3330, Train AUC: 0.9834, Test AUC: 0.9791\n","Epoch: 170, Loss: 0.3283, Train AUC: 0.9835, Test AUC: 0.9795\n","Epoch: 180, Loss: 0.3282, Train AUC: 0.9839, Test AUC: 0.9800\n","Epoch: 190, Loss: 0.3231, Train AUC: 0.9840, Test AUC: 0.9800\n","Epoch: 200, Loss: 0.3239, Train AUC: 0.9845, Test AUC: 0.9802\n","Epoch: 210, Loss: 0.3189, Train AUC: 0.9840, Test AUC: 0.9809\n","Epoch: 220, Loss: 0.3158, Train AUC: 0.9855, Test AUC: 0.9804\n","Epoch: 230, Loss: 0.3076, Train AUC: 0.9859, Test AUC: 0.9816\n","Epoch: 240, Loss: 0.3051, Train AUC: 0.9865, Test AUC: 0.9821\n","Epoch: 250, Loss: 0.2980, Train AUC: 0.9870, Test AUC: 0.9819\n","Epoch: 260, Loss: 0.3041, Train AUC: 0.9869, Test AUC: 0.9832\n","Epoch: 270, Loss: 0.2947, Train AUC: 0.9868, Test AUC: 0.9820\n","Epoch: 280, Loss: 0.3044, Train AUC: 0.9877, Test AUC: 0.9842\n","Epoch: 290, Loss: 0.2908, Train AUC: 0.9880, Test AUC: 0.9845\n","Epoch: 300, Loss: 0.2854, Train AUC: 0.9885, Test AUC: 0.9843\n","Epoch: 310, Loss: 0.2807, Train AUC: 0.9886, Test AUC: 0.9844\n","Epoch: 320, Loss: 0.2797, Train AUC: 0.9888, Test AUC: 0.9846\n","Epoch: 330, Loss: 0.2771, Train AUC: 0.9889, Test AUC: 0.9848\n","Epoch: 340, Loss: 0.2769, Train AUC: 0.9891, Test AUC: 0.9847\n","Epoch: 350, Loss: 0.2739, Train AUC: 0.9892, Test AUC: 0.9836\n","Epoch: 360, Loss: 0.2751, Train AUC: 0.9895, Test AUC: 0.9844\n","Epoch: 370, Loss: 0.2704, Train AUC: 0.9894, Test AUC: 0.9853\n","Epoch: 380, Loss: 0.2702, Train AUC: 0.9894, Test AUC: 0.9854\n","Epoch: 390, Loss: 0.2656, Train AUC: 0.9897, Test AUC: 0.9856\n","Epoch: 400, Loss: 0.2662, Train AUC: 0.9900, Test AUC: 0.9855\n","Epoch: 410, Loss: 0.2628, Train AUC: 0.9901, Test AUC: 0.9850\n","Epoch: 420, Loss: 0.2584, Train AUC: 0.9903, Test AUC: 0.9852\n","Epoch: 430, Loss: 0.2701, Train AUC: 0.9906, Test AUC: 0.9849\n","Epoch: 440, Loss: 0.2588, Train AUC: 0.9894, Test AUC: 0.9847\n","Epoch: 450, Loss: 0.2570, Train AUC: 0.9909, Test AUC: 0.9848\n","Epoch: 460, Loss: 0.2579, Train AUC: 0.9890, Test AUC: 0.9850\n","Epoch: 470, Loss: 0.2555, Train AUC: 0.9904, Test AUC: 0.9854\n","Epoch: 480, Loss: 0.2579, Train AUC: 0.9913, Test AUC: 0.9862\n","Epoch: 490, Loss: 0.2483, Train AUC: 0.9917, Test AUC: 0.9859\n","Epoch: 500, Loss: 0.2460, Train AUC: 0.9916, Test AUC: 0.9868\n","Epoch: 510, Loss: 0.2416, Train AUC: 0.9918, Test AUC: 0.9869\n","Epoch: 520, Loss: 0.2403, Train AUC: 0.9920, Test AUC: 0.9870\n","Epoch: 530, Loss: 0.2353, Train AUC: 0.9925, Test AUC: 0.9864\n","Epoch: 540, Loss: 0.2350, Train AUC: 0.9925, Test AUC: 0.9871\n","Epoch: 550, Loss: 0.2317, Train AUC: 0.9926, Test AUC: 0.9870\n","Epoch: 560, Loss: 0.2273, Train AUC: 0.9930, Test AUC: 0.9864\n","Epoch: 570, Loss: 0.2322, Train AUC: 0.9930, Test AUC: 0.9866\n","Epoch: 580, Loss: 0.2251, Train AUC: 0.9932, Test AUC: 0.9870\n","Epoch: 590, Loss: 0.2331, Train AUC: 0.9934, Test AUC: 0.9868\n","Prediction accuracy: 0.9461\n"]}],"source":["gat_model = train_model(epoch, \"GAT\", data_train, data_test, train_loader, test_loader, device)\n","test_model(gat_model, data_total, data_test, device)"]},{"cell_type":"markdown","metadata":{"id":"CxMmQRCdCP3E"},"source":["# Application: 6 vs 6 win strategy (ordering)"]},{"cell_type":"markdown","metadata":{"id":"sVgBNRS1CP3E"},"source":["\n","Implementing an application that dynamically suggests the Pokemon you should send out to win when the order of the opponent's Pokemon appears randomly."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"OylBiT6uuuKv","executionInfo":{"status":"ok","timestamp":1716816276203,"user_tz":-540,"elapsed":336,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["def node_feature_update(winner, loser, data_battle):\n","  \"\"\"\n","  Update the node feature of the winner and loser pokemon after the battle\n","\n","  INPUT\n","  winner: winner pokemon id\n","  loser: loser pokemon id\n","  data_battle: data object for the battle\n","\n","  \"\"\"\n","  damage = sum(data_battle.x[loser][i].item() for i in range(2, 8))\n","  data_battle.x[winner][1] -= damage\n","  data_battle.x[winner][0] = sum(data_battle.x[winner][i].item() for i in range(1, 8))\n","\n","  return data_battle\n","\n","\n","def find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon=None):\n","  \"\"\"\n","  If my_pokemon is None, find the pokemon to fight against the opponent pokemon and return the result.\n","  If there is no pokemon that can win, choose the pokemon with the lowest stats among them and update the node feature\n","  If there are pokemons that can win, choose the pokemon with the lowest probability of winning among them and update the node feature\n","\n","  If my_pokemon is not None, return the result of the fight.\n","\n","  INPUT\n","  model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n","  opponents: list of opponent pokemon id\n","  ours: list of our alive pokemon id\n","  opp_idx: index of the opponent pokemon in the opponents list\n","  data_battle: data object for the battle\n","  my_pokemon: my pokemon that won in previous round. None if we lose.\n","\n","  OUTPUT\n","  win: 1 if we lose, 2 if we win (0: default)\n","  my_pokemon: my pokemon participating in this round / if my_pokemon is not None, then return my_pokemon is None\n","  \"\"\"\n","  win = 0\n","  node1 = opponents[opp_idx]\n","  my_winner_pokemon = [] # (pokemon_id, win_prob) list\n","\n","  # 첫 라운드거나 이전 라운드에서 우리가 패배한 경우 (새로운 my_pokemon을 찾아야 하는 경우)\n","  if my_pokemon==None:\n","    # 남아있는 내 포켓몬들을 다 돌아보면서 승리할 확률이 더 높은 pokemon들을 my_winner_pokemon에 prediction score와 함께 append\n","    for our_idx in range(len(remained_ours)):\n","      node2 = remained_ours[our_idx]\n","      prediction, reverse_prediction = predict(model, node1, node2, data_battle.to(device), device) # 우리 pokemon이 이길 prediction score\n","      if prediction > reverse_prediction:\n","        my_winner_pokemon.append((remained_ours[our_idx], prediction))\n","\n","    if not len(my_winner_pokemon):\n","      # 이길 수 있는 pokemon이 없다면 전체적인 stat이 높은 순서로 정렬하여 가장 약한 pokemon이 나가도록 한다.\n","      sorted_stats_idx = sorted(range(len(remained_ours)), key=lambda i: data_battle.x[remained_ours[i]][0].item())\n","\n","      my_pokemon = remained_ours[sorted_stats_idx[0]] # sorting한 것에서 맨 앞에(stat이 가장 작은) 있는 index의 pokemon을 내보낸다.\n","      win = 1 # we lose\n","    else:\n","      # 이길 수 있는 pokemon이 있다면 -> prob 크기 순서대로 정렬하고 prob 가장 작은 pokemon을 ordering에 추가\n","      my_winner_pokemon = sorted(my_winner_pokemon, key=lambda pokemon_pair: pokemon_pair[1]) # prediction score 값을 토대로 sorting\n","      winner = my_winner_pokemon[0][0]\n","      my_pokemon = winner\n","      win = 2 # we win\n","\n","    return win, my_pokemon\n","\n","  # 이전 라운드에서 우리 포켓몬이 이긴 경우\n","  else:\n","    # opponents[opp_idx]와 my_pokemon의 승부 결과를 return해야 한다.\n","    node2 = my_pokemon\n","    prediction, reverse_prediction = predict(model, node1, node2, data_battle.to(device), device) # 우리 pokemon이 이길 prediction score\n","    if prediction > reverse_prediction:\n","      win = 2 # we win\n","    else:\n","      win = 1\n","    return win, None\n","\n","def search_pokemon_name(pokemon_id):\n","  for i in range(len(pokemon_data)):\n","    if pokemon_data.loc[i][\"#\"]==pokemon_id:\n","      return pokemon_data.loc[i][\"Name\"]\n","\n","def print_simulate_msg(win, opponent, our):\n","  opponent_pokemon_name = search_pokemon_name(opponent)\n","  our_pokemon_name = search_pokemon_name(our)\n","  print(\"opponent: {} ({})\".format(opponent, opponent_pokemon_name))\n","  print(\"our: {} ({})\".format(our, our_pokemon_name))\n","  if (win ==1):\n","    # opponent win\n","    print(\"winner: {}\".format(opponent))\n","  else:\n","    # our win\n","    print(\"winner: {}\".format(our))\n","  print(\"\")\n","\n","def update_remained_pokemon(win, my_pokemon, opp_idx, opponent_pokemon, remained_opponents, remained_ours, data_battle):\n","  \"\"\"\n","  Based on the result of the fight, update the opponent/our remained pokemon list and update the survived pokemon hp feature value.\n","\n","  INPUT\n","  win: the result of the fight\n","  my_pokemon: the pokemon fought in this round\n","\n","  \"\"\"\n","  # 패배한 포켓몬은 remained list에서 제거\n","  if (win == 1):\n","    # opponent win -> our pokemon이 제거되어야 한다\n","    data_battle = node_feature_update(opponents[opp_idx], my_pokemon, data_battle)\n","\n","    remained_ours.remove(my_pokemon)\n","  else:\n","    # we win -> opponent pokemon이 제거되어야 한다.\n","    data_battle = node_feature_update(my_pokemon, opponents[opp_idx], data_battle)\n","\n","    remained_opponents.remove(opponents[opp_idx])\n","    opp_idx += 1 # battle 할 다음 opponent 포켓몬을 indexing 하도록 한다.\n","\n","  return remained_opponents, remained_ours, opp_idx, data_battle"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"vG6dESZwuvgO","executionInfo":{"status":"ok","timestamp":1716816276751,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["# model input: data, edge_index, neg_edge_index\n","# edge index를 생성하여 predict를 하자.\n","# node 1(head): loser, node 2(tail): winner이라는 것에 대해서 추측하는 것\n","\n","# 6마리의 pokemon을 받는다.\n","# edge_index: [[losers], [winners]]인데 그냥 [[opponent's pokemons], [our pokemons]]로 넣고 edge prediction 진행\n","def simulate(model, opponents, ours, data_battle):\n","  \"\"\"\n","  Simulate the battle between our 6 pokemons and opponent's 6 pokemons\n","\n","  INPUT\n","  model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n","  opponents: list of opponent's 6 pokemon ids\n","  ours: list of our 6 pokemon ids\n","  data_battle: data object for the battle\n","  \"\"\"\n","  random.shuffle(opponents) # opponent\n","  win = 0 # 0: start, 1: opponent win , 2: ours win\n","  opp_idx, our_idx = 0, 0\n","  remained_opponents, remained_ours = copy.deepcopy(opponents), ours\n","  round = 1 # round #\n","\n","  while (len(remained_opponents)!=0 and len(remained_ours)!=0): # ours 또는 opponents 중 하나가 0이 될 때까지 repeat\n","    print(\"Round {}.\".format(round))\n","    if win==2: # 전 라운드에 우리가 이겼다면 my_pokemon이 input으로 들어가야 한다.\n","      win, _ = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon)\n","    else: # 상대 팀이 이겼었다면 my_pokemon 새로 뽑아야 한다.\n","      win, my_pokemon = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle)\n","    print_simulate_msg(win, opponents[opp_idx], my_pokemon)\n","    remained_opponents, remained_ours, opp_idx,data_battle = update_remained_pokemon(win, my_pokemon, opp_idx, opponents[opp_idx], remained_opponents, remained_ours, data_battle)\n","\n","    round += 1\n","\n","  if (len(remained_ours)==0):\n","    print(\"You lose...\")\n","\n","  else:\n","    print(\"You win!\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAqESd3XuybM","outputId":"517c6658-b1bb-4af5-e3b6-9c16e65cf4c2","executionInfo":{"status":"ok","timestamp":1716816278291,"user_tz":-540,"elapsed":1160,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1.\n","opponent: 382 (Milotic)\n","our: 123 (Kangaskhan)\n","winner: 123\n","\n","Round 2.\n","opponent: 155 (Snorlax)\n","our: 123 (Kangaskhan)\n","winner: 155\n","\n","Round 3.\n","opponent: 155 (Snorlax)\n","our: 635 (Gothita)\n","winner: 635\n","\n","Round 4.\n","opponent: 610 (Basculin)\n","our: 635 (Gothita)\n","winner: 610\n","\n","Round 5.\n","opponent: 610 (Basculin)\n","our: 356 (Spoink)\n","winner: 610\n","\n","Round 6.\n","opponent: 610 (Basculin)\n","our: 718 (Chespin)\n","winner: 610\n","\n","Round 7.\n","opponent: 610 (Basculin)\n","our: 357 (Grumpig)\n","winner: 610\n","\n","Round 8.\n","opponent: 610 (Basculin)\n","our: 775 (Sliggoo)\n","winner: 610\n","\n","You lose...\n"]}],"source":["\n","opponents = [132, 155, 610, 382, 100, 519]\n","ours = [718, 357, 775, 356, 123, 635]\n","\n","\n","model = [gcn_model, graphsage_mean_model, graphsage_max_model, gat_model]\n","data_battle = copy.deepcopy(data_total)\n","simulate(model[3], opponents, ours, data_battle)"]},{"cell_type":"markdown","metadata":{"id":"euNqF3yBLM50"},"source":["## Short output simulation"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"HNkLC6DGCP3F","executionInfo":{"status":"ok","timestamp":1716816279732,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["# # model input: data, edge_index, neg_edge_index\n","# # edge index를 생성하여 predict를 하자.\n","# # node 1(head): loser, node 2(tail): winner이라는 것에 대해서 추측하는 것\n","\n","# # 6마리의 pokemon을 받는다.\n","# # edge_index: [[losers], [winners]]인데 그냥 [[opponent's pokemons], [our pokemons]]로 넣고 edge prediction 진행\n","# def short_simulate(model, opponents, ours, data_battle):\n","#   \"\"\"\n","#   Simulate the battle between our 6 pokemons and opponent's 6 pokemons (short result version)\n","\n","#   INPUT\n","#   model: gcn model, graphsage_mean model, graphsage_max_model, gat_model\n","#   opponents: list of opponent's 6 pokemon ids\n","#   ours: list of our 6 pokemon ids\n","#   data_battle: data object for the battle\n","#   \"\"\"\n","#   random.shuffle(opponents) # opponent\n","#   win = 0 # 0: start, 1: opponent win , 2: ours win\n","#   opp_idx, our_idx = 0, 0\n","#   remained_opponents, remained_ours = copy.deepcopy(opponents), ours\n","#   round = 1 # round #\n","#   printing = True\n","\n","#   while (len(remained_opponents)!=0 and len(remained_ours)!=0): # ours 또는 opponents 중 하나가 0이 될 때까지 repeat\n","#     if (len(remained_opponents)==1 or len(remained_ours)==1):\n","#       printing=True\n","#     if printing:\n","#       print(\"Round {}.\".format(round))\n","#     if win==2: # 전 라운드에 우리가 이겼다면 my_pokemon이 input으로 들어가야 한다.\n","#       win, _ = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle, my_pokemon)\n","#     else: # 상대 팀이 이겼었다면 my_pokemon 새로 뽑아야 한다.\n","#       win, my_pokemon = find_pokemon(model, opponents, opp_idx, remained_ours, data_battle)\n","\n","#     if printing:\n","#       print_simulate_msg(win, opponents[opp_idx], my_pokemon)\n","#     if round == 2:\n","#       print(\"...\")\n","#       print()\n","#       printing=False\n","\n","#     remained_opponents, remained_ours, opp_idx,data_battle = update_remained_pokemon(win, my_pokemon, opp_idx, opponents[opp_idx], remained_opponents, remained_ours, data_battle)\n","\n","#     round += 1\n","\n","#   if (len(remained_ours)==0):\n","#     print(\"You lose...\")\n","\n","#   else:\n","#     print(\"You win!\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"UcemBbl0CP3F","executionInfo":{"status":"ok","timestamp":1716816281077,"user_tz":-540,"elapsed":346,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"outputs":[],"source":["# ours = [132, 155, 610, 382, 100, 519]\n","# opponents = [718, 357, 775, 356, 123, 635]\n","\n","\n","# model = [gcn_model, graphsage_mean_model, graphsage_max_model, gat_model]\n","# data_battle = copy.deepcopy(data_total)\n","# short_simulate(model[3], opponents, ours, data_battle)"]},{"cell_type":"code","source":[],"metadata":{"id":"Gb7jtO4mOXiL","executionInfo":{"status":"ok","timestamp":1716816281654,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyein Gu","userId":"17771678136426456982"}}},"execution_count":20,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}